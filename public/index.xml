<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Arie Spirgel</title>
    <link>/</link>
      <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    <description>Arie Spirgel</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Tue, 10 Mar 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>Arie Spirgel</title>
      <link>/</link>
    </image>
    
    <item>
      <title>Why Use R for Institutional Research? Part 1, Many Models</title>
      <link>/post/ipeds-many-models/01-r-for-institutional-research/</link>
      <pubDate>Tue, 10 Mar 2020 00:00:00 +0000</pubDate>
      <guid>/post/ipeds-many-models/01-r-for-institutional-research/</guid>
      <description>


&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;I first heard about R when I was in graduate school in 2008 and fellow students used it to analyze their data. I didn’t bother to learn it at the time because, one, I didn’t see the benefit of it, and two, I assumed that without any programming experience, it was too difficult. So I continued with my same workflow: Clean data and make charts in Excel, import data into SPSS to analyze it, and then paste my output into a Word document and write up the results.&lt;/p&gt;
&lt;p&gt;I started working in institutional research in 2013 and I still hadn’t made the switch to R, but was beginning to see the drawbacks of my workflow and the upside of coding. I often had to generate the same reports on a regular basis where the only thing that would change was the data. Or I’d have to generate the same charts or tables for each of the 15 colleges at the university, and on bad days, each of the 150-something majors. This quickly became unsustainable when I would, for example, get one of these requests late on a Friday afternoon and had to have it ready for a Board meeting on Monday. R increasingly seemed like a preferable alternative.&lt;/p&gt;
&lt;p&gt;Fast-forward 7 years and my SPSS license has long since expired, I don’t recall the last time I made a chart in Excel, and the only thing I use Word for is making grocery lists. Today, my entire workflow exists inside of R.&lt;/p&gt;
&lt;p&gt;In the intervening years, I have frequently met other institutional researchers who are stuck in the same mindset I was in 2008: For people who have never coded, R seems too overwhelming to learn, and even if they were to learn it, they do not see the benefits of doing so. In future posts I plan to address the former, but in this series of posts I want to address the latter: What’s the point of learning R for institutional research? Rather than list all of the reasons why R is an excellent choice for doing institutional research, I want to show examples of how I use it. In this post, I’ll demonstrate the scenario of using R to run many models.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;If you are not an R user, do not worry about the details of the code below, but instead, pay attention to what the code is capable of producing&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;running-one-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Running One Model&lt;/h2&gt;
&lt;p&gt;Whether you want to predict future enrollment or explain why some students do not graduate, modeling is an important skill in institutional research. To show how to run a linear model in R, for all colleges and universities in the &lt;a href=&#34;https://nces.ed.gov/ipeds/use-the-data&#34;&gt;IPEDS Data Center&lt;/a&gt;, I downloaded their state, one year retention rates (i.e., the percent of first-time in college students who re-enroll their second fall term), student-faculty ratios, and the number of undergraduate applications they received for a given year. Here is the code for reading in the data and what the first five rows of data look like:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(broom)
library(drlib)

ipeds &amp;lt;- read_rds(&amp;quot;processed-data/ipeds-sfr.rds&amp;quot;)

head(ipeds, 5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 5 x 5
##   name            state   undergrad_appli~ retention_rate student_faculty_~
##   &amp;lt;chr&amp;gt;           &amp;lt;chr&amp;gt;              &amp;lt;dbl&amp;gt;          &amp;lt;dbl&amp;gt;             &amp;lt;dbl&amp;gt;
## 1 Educational Te~ Puerto~               NA             11                21
## 2 A T Still Univ~ Missou~               NA             NA                NA
## 3 Aaniiih Nakoda~ Montana               NA             34                10
## 4 ABC Adult Scho~ Califo~               NA             NA                 4
## 5 ABC Beauty Aca~ Texas                 NA             25                10&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this contrived example, to build a linear model with retention rate as the outcome and student-faculty ratio and number of undergraduate applications as the predictors, I took the &lt;code&gt;ipeds&lt;/code&gt; data frame, piped it (&lt;code&gt;%&amp;gt;%&lt;/code&gt;) to the &lt;code&gt;lm&lt;/code&gt; function, and then cleaned up the results with the &lt;code&gt;tidy()&lt;/code&gt; function from the broom package. This gives us the model results:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ipeds %&amp;gt;% 
  lm(retention_rate ~ student_faculty_ratio + undergrad_applicants, data = .) %&amp;gt;% 
  tidy()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 5
##   term                   estimate std.error statistic  p.value
##   &amp;lt;chr&amp;gt;                     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;
## 1 (Intercept)           76.2      0.868         87.8  0.      
## 2 student_faculty_ratio -0.326    0.0589        -5.54 3.45e- 8
## 3 undergrad_applicants   0.000504 0.0000315     16.0  3.03e-54&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;At this point you may be thinking, “So what? I can just easily do the same thing in SPSS, or even Excel”. That is true, but what if instead of running one model, you had to run 150?&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;running-many-models&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Running Many Models&lt;/h2&gt;
&lt;p&gt;As part of our university’s strategic business plan, I recently had to create separate models for each of the 150-something majors at the school. If I were still using SPSS, this would mean:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;days of pointing and clicking and copying and pasting.&lt;/li&gt;
&lt;li&gt;doing the same thing over and over again each time the project requirements changed, which is an inevitability.&lt;/li&gt;
&lt;li&gt;having no documentation about the decisions I made because everything was done by pointing and clicking.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Returning to the original data set, let’s say I wanted repeat the same model above, but separately for each state. Using R, I first filter the data to only include states with at least 50 schools (an arbitrarily chosen cutoff point):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ipeds &amp;lt;- ipeds %&amp;gt;% 
  add_count(state) %&amp;gt;% 
  filter(n &amp;gt;= 50)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, I turn the model into a function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;state_regression &amp;lt;- function(df) {
 df %&amp;gt;% 
  lm(retention_rate ~ student_faculty_ratio + undergrad_applicants, data = .) 
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From there, I can apply the function to each state in the data set, which returns a data frame with the model results for each state:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ipeds_model &amp;lt;- ipeds %&amp;gt;% 
  group_by(state) %&amp;gt;% 
  nest() %&amp;gt;% 
  mutate(model = map(data, state_regression),
         tidy_model = map(model, tidy)) %&amp;gt;% 
  unnest(tidy_model) 

head(ipeds_model, 5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 5 x 8
## # Groups:   state [2]
##   state   data       model term       estimate std.error statistic  p.value
##   &amp;lt;chr&amp;gt;   &amp;lt;list&amp;gt;     &amp;lt;lis&amp;gt; &amp;lt;chr&amp;gt;         &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;
## 1 Puerto~ &amp;lt;tibble [~ &amp;lt;lm&amp;gt;  (Intercep~ 87.5       5.80        15.1  2.48e-18
## 2 Puerto~ &amp;lt;tibble [~ &amp;lt;lm&amp;gt;  student_f~ -0.869     0.315       -2.76 8.68e- 3
## 3 Puerto~ &amp;lt;tibble [~ &amp;lt;lm&amp;gt;  undergrad~  0.00208   0.00140      1.49 1.45e- 1
## 4 Missou~ &amp;lt;tibble [~ &amp;lt;lm&amp;gt;  (Intercep~ 84.5       5.46        15.5  1.91e-22
## 5 Missou~ &amp;lt;tibble [~ &amp;lt;lm&amp;gt;  student_f~ -1.07      0.458       -2.33 2.30e- 2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, with a separate model for each state all in a data frame, I can treat the model output like I would any other data. For example, here, I visualize the model results for each state:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ipeds_model %&amp;gt;% 
  filter(term != &amp;quot;(Intercept)&amp;quot;) %&amp;gt;% 
  mutate(term = if_else(term == &amp;quot;student_faculty_ratio&amp;quot;,
                        &amp;quot;Student/Faculty Ratio&amp;quot;, &amp;quot;# of Undergraduate Applications&amp;quot;)) %&amp;gt;% 
  ggplot(aes(x = reorder_within(state, -estimate, term),
             y = estimate,
             ymin = estimate - (2 * std.error),
             ymax = estimate + (2 * std.error))) +
  geom_pointrange(color = &amp;quot;grey60&amp;quot;) +
  coord_flip() +
  guides(color = FALSE) +
  facet_wrap(~term, scales = &amp;quot;free&amp;quot;, ncol = 2) +
  theme_classic() +
  scale_x_reordered() +
  geom_hline(yintercept = 0, linetype = 2) +
  labs(
    title = str_wrap(&amp;quot;Is First-Year Retention Associated with Student-Faulty Ratio and/or Undergraduate Applications?&amp;quot;, 75),
       subtitle = &amp;quot;Limited to states with at least 50 schools&amp;quot;,
       caption = &amp;quot;Source: IPEDS Data Center&amp;quot;,
       x = NULL, y = &amp;quot;Estimate&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ipeds-many-models/01-r-for-institutional-research_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Claiming that there is more friction to learning R than there is to learning menu-driven tools is like saying learning to microwave TV dinners is easier than learning to cook the same meal from scratch. Both points might be true, but they obscure the ultimate goals of each: R, like cooking, unconstrains you, giving you the freedom to create whatever fills your imagination. And whether it’s running models for 150 majors or making soup for a large dinner party, learning to code and learning to cook can make your work not only more tenable, but more enjoyable, and in the long-run, simpler.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Introduction to R and ggplot2</title>
      <link>/talk/2020-wcc-ggplot2/</link>
      <pubDate>Thu, 05 Mar 2020 12:00:00 +0000</pubDate>
      <guid>/talk/2020-wcc-ggplot2/</guid>
      <description>


&lt;p&gt;Learn how to visualize data using R and ggplot2!&lt;/p&gt;
&lt;p&gt;Whether you’re interested in data science, business, or working on a dissertation or research project, knowing how to visualize data is a vital skill. In this free, 2.5 hour workshop, you’ll be introduced to the R programming language and learn to visualize data using ggplot2. In the last 30 minutes of the workshop, Janine Morris from NSU’s Writing and Communication Center will talk about the features of effective data visualizations.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Fellow R Instructors: Beware of the Curse of Knowledge!</title>
      <link>/post/curse-of-knowledge/curse-of-knowledge/</link>
      <pubDate>Fri, 14 Feb 2020 00:00:00 +0000</pubDate>
      <guid>/post/curse-of-knowledge/curse-of-knowledge/</guid>
      <description>


&lt;div id=&#34;the-curse-of-knowledge-in-everyday-life&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The Curse of Knowledge in Everyday Life&lt;/h2&gt;
&lt;p&gt;Several years ago my friend Lauren asked me for my recipe for BBQ seitan. I love food-related conversation, so I wasted no time. “Start by sauteing some chopped onion in oil…”, and as quickly as I began, she cut me off. “Hold on,” she interjected. “What kind of oil do you use? How much? How high do you turn the heat?”&lt;/p&gt;
&lt;p&gt;Dissecting the conversation, what happened was that I implicitly made the absurd assumption that knowledge that is in my head must be in hers (i.e., “Use however much of whatever oil you’d like to at whatever heat you normally saute”). In other words, I fell victim to the &lt;a href=&#34;https://en.wikipedia.org/wiki/Curse_of_knowledge&#34;&gt;curse of knowledge&lt;/a&gt;. I’m &lt;strong&gt;not&lt;/strong&gt; an expert cook - just ask my wife who always keeps the salt and pepper shaker within arm’s reach when I prepare a meal - but I did naively explain the recipe to Lauren as if she possessed my idiosyncratic definition of “saute”.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-curse-of-knowledge-when-teaching-r&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The Curse of Knowledge When Teaching R&lt;/h2&gt;
&lt;p&gt;Scenarios like this are universal, and most of the time, they are harmless. However, they can be frustrating when people have invested time and money to learn R from you. Even if you yourself are relatively to new to R, it is easy to take for granted all that you know and what it’s like to be a true beginner. Consider the following questions and confusion that a new R user might have when you ask them to do something as seemingly innocuous as running a line of &lt;code&gt;read_csv()&lt;/code&gt; code you’ve provided:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;“I just bought a book that says to use &lt;code&gt;read.csv()&lt;/code&gt;, but you use &lt;code&gt;read_csv()&lt;/code&gt;. They are so similar they must do exactly the same thing, right?”&lt;/li&gt;
&lt;li&gt;“Excuse me, but are you saying &lt;em&gt;tibble&lt;/em&gt;? Do you mean &lt;em&gt;table&lt;/em&gt;?”&lt;/li&gt;
&lt;li&gt;“I tried running &lt;code&gt;read_csv()&lt;/code&gt; but I got an error saying the function couldn’t be found. How does &lt;em&gt;that&lt;/em&gt; make sense?”&lt;/li&gt;
&lt;li&gt;“I thought you said colons aren’t allowed in function names, so why did you write &lt;code&gt;readr::read_csv()&lt;/code&gt;?”&lt;/li&gt;
&lt;li&gt;“The code you shared says &lt;code&gt;read_csv(&amp;quot;raw-data/survey-results.csv&amp;quot;)&lt;/code&gt; but I changed the &lt;code&gt;/&lt;/code&gt; to &lt;code&gt;\&lt;/code&gt; because that’s what the folders look like on my computer and now it doesn’t work. WTF, right?!”&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Not all of your students will tell you when they’re stuck, and because you can’t read their minds, what are you to do? &lt;strong&gt;Ask them!&lt;/strong&gt; Whether it’s a one day workshop or a semester long course, giving frequent, brief, assessments will help you identify areas of confusion and guide your lessons.&lt;/p&gt;
&lt;p&gt;You might be thinking that when you have a large group of people, resolving every question that every student has is unrealistic. That may be true, but it is a shame when a student falls behind because an instructor misses an opportunity for a simple clarification. Consider the following (intentionally confusing) passage from Bransford and Johnson (1972):&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The procedure is actually quite simple. First you arrange things into different groups… Of course, one pile may be sufficient depending on how much there is to do. If you have to go somewhere else due to lack of facilities that is the next step, otherwise you are pretty well set. It is important not to overdo any particular endeavor. That is, it is better to do too few things at once than too many. In the short run this may not seem important, but complications from doing too many can easily arise. A mistake can be expensive as well… At first the whole procedure will seem complicated. Soon, however, it will become just another facet of life. It is difficult to foresee any end to the necessity for this task in the immediate future, but then one never can tell. After the procedure is completed one arranges the materials into different groups again. Then they can be put into their appropriate places. Eventually they will be used once more and the whole cycle will have to be repeated. However, that is part of life. (Bransford and Johnson 1972 p. 722)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;If you’ve never seen this passage before, it probably makes little sense to you and its details are unlikely to stick in your mind. But if before you read it I gave you the passage’s title - &lt;em&gt;Washing Clothes&lt;/em&gt; - it would suddenly become much clearer. There are plenty of “washing clothes” examples in R, and as the instructor, it’s your job to construct an environment that helps you identify them.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Frequent assessments will alert you when you succumb to the curse of knowledge and help you to correct your biases. If you’re teaching R - or for that matter, anything - and you’re not regularly checking in on what your students know and what their misconceptions are, it’s worth asking yourself what your goals are, because maximizing student understanding may not be one of them.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Welcome to the Tidyverse: Part 2</title>
      <link>/talk/colorado-ed-part-2/</link>
      <pubDate>Fri, 17 Jan 2020 11:00:00 +0000</pubDate>
      <guid>/talk/colorado-ed-part-2/</guid>
      <description>


&lt;p&gt;Part 2 of “&lt;a href=&#34;https://github.com/rstudio-education/welcome-to-the-tidyverse&#34;&gt;Welcome to the Tidyverse&lt;/a&gt;”, which covers the following topics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Modeling with &lt;code&gt;modelr&lt;/code&gt; and &lt;code&gt;broom&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Reporting with &lt;code&gt;rmarkdown&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Welcome to the Tidyverse: Part 1</title>
      <link>/talk/colorado-ed-part-1/</link>
      <pubDate>Tue, 14 Jan 2020 11:00:00 +0000</pubDate>
      <guid>/talk/colorado-ed-part-1/</guid>
      <description>


&lt;p&gt;Part 1 of “&lt;a href=&#34;https://github.com/rstudio-education/welcome-to-the-tidyverse&#34;&gt;Welcome to the Tidyverse&lt;/a&gt;”, which covers the following topics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Introduction to R.&lt;/li&gt;
&lt;li&gt;Visualization with &lt;code&gt;ggplot2&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Tranformation with &lt;code&gt;dplyr&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>ggplot2: Going Beyond the Defaults</title>
      <link>/post/ggplotredo1/geographic-growth-midwest/</link>
      <pubDate>Sun, 05 Jan 2020 00:00:00 +0000</pubDate>
      <guid>/post/ggplotredo1/geographic-growth-midwest/</guid>
      <description>


&lt;p&gt;With ggplot2 - the ubiquitous tool for making plots in R - you can create beautiful data visualizations without doing much to the defaults. By applying the template below (see &lt;a href=&#34;https://r4ds.had.co.nz/&#34;&gt;R for Data Science&lt;/a&gt;), adding a theme (e.g., &lt;code&gt;theme_light()&lt;/code&gt;), and giving your chart custom labels, you can have a publication-ready visualization.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = &amp;lt;DATA&amp;gt;) + 
  &amp;lt;GEOM_FUNCTION&amp;gt;(
     mapping = aes(&amp;lt;MAPPINGS&amp;gt;),
     stat = &amp;lt;STAT&amp;gt;, 
     position = &amp;lt;POSITION&amp;gt;
  ) +
  &amp;lt;COORDINATE_FUNCTION&amp;gt; +
  &amp;lt;FACET_FUNCTION&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But the more I pay attention to how people respond to visualizations, the more I realize how minor improvements can make a major difference. Like cooking, where adding a little bit of salt or giving a dish a few extra minutes in the oven can transform a meal from acceptable to outstanding, relatively small changes to a chart can do the same.&lt;/p&gt;
&lt;p&gt;Take the example below, in which one of &lt;a href=&#34;http://stephanieevergreen.com/before-and-after-business-slides/&#34;&gt;Stephanie Evergreen’s&lt;/a&gt; clients started with the slide on the top, and she helped them create the one below it:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/evergreen-before.png&#34; width=&#34;400&#34; /&gt;&lt;img src=&#34;/img/evergreen-after.png&#34; width=&#34;400&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Both charts contain the same information, and even if you can’t express why, you just &lt;em&gt;know&lt;/em&gt; the one on the bottom is better. Continuing with the cooking analogy, the charts are like two Mexican restaurants that use the same ingredients, but at one, the guacamole is fresher, the rice is more flavorful, and the tortillas are made in house.&lt;/p&gt;
&lt;p&gt;ggplot2 was designed so users can &lt;a href=&#34;https://r4ds.had.co.nz/data-visualisation.html&#34;&gt;build any plot that they can imagine&lt;/a&gt;, so as attractive as its defaults are, my goal with this series of posts is to venture beyond the minor design adjustments I typically make and learn to tweak charts from ordinary to outstanding. My first goal was to use ggplot2 to reproduce the chart that Dr. Evergreen created for her client, which based on her post, I think she did in Excel.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(scales)
library(cowplot)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;step-0-create-the-dataset&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 0: Create the Dataset&lt;/h2&gt;
&lt;p&gt;In addition to creating the data set, I used &lt;code&gt;fct_reorder()&lt;/code&gt; so the bars will appear in order from highest to lowest growth in the chart.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;growth &amp;lt;- tribble(
  ~region,               ~growth, ~group,
  &amp;quot;Large city, Midwest&amp;quot;,     .2,   &amp;quot;Midwest&amp;quot;,
  &amp;quot;Large city, East Coast&amp;quot;, .175,   &amp;quot;Other&amp;quot;,
  &amp;quot;Medium city, South&amp;quot;,      .165,  &amp;quot;Other&amp;quot;,
  &amp;quot;Medium city, Midwest&amp;quot;,    .165,  &amp;quot;Midwest&amp;quot;,
  &amp;quot;Small city, Midwest&amp;quot;,     .14,   &amp;quot;Midwest&amp;quot;, 
  &amp;quot;Large city, West coast&amp;quot;,  .10,   &amp;quot;Other&amp;quot;
) %&amp;gt;% 
  mutate(region = fct_reorder(region, growth)) &lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;step-1-make-the-foundational-chart&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 1: Make the Foundational Chart&lt;/h2&gt;
&lt;p&gt;This chart contains all of the information that the final chart contains, but it’s like the decent restaurant you’ll never return to: fine, but unmemorable. In this step, I also narrowed the width of the bars, a subtle alteration that improves the feel of the chart as it gets closer to the finished product.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(p &amp;lt;- growth %&amp;gt;% 
  ggplot(aes(x = region, y = growth, fill = group)) + 
  geom_col(width = .7) + 
  coord_flip() + 
  labs(x = NULL, y = NULL, 
       title = &amp;quot;Geographic growth dominated by Midwest.&amp;quot;,
       subtitle = &amp;quot;5 year growth&amp;quot;,
       caption = &amp;quot;Source: Our Smart Source 2015&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ggplotredo1/geographic-growth-midwest_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;step-2-update-the-colors-and-remove-the-legend&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 2: Update the Colors and Remove the Legend&lt;/h2&gt;
&lt;p&gt;Even if you like the default ggplot2 colors - which I very much do - putting a dark color next to a muted color does a better job of highlighting a conclusion you might want to draw attention to. And by juxtaposing the green and gray, in combination with the chart’s title, the legend becomes extraneous and can be removed.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(p &amp;lt;- p +
  scale_fill_manual(values = c(&amp;quot;#4D643D&amp;quot;, &amp;quot;#D7DBDD&amp;quot;)) +
  guides(fill = FALSE))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ggplotredo1/geographic-growth-midwest_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;step-3-white-background-and-minimal-gridlines&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 3: White Background and Minimal Gridlines&lt;/h2&gt;
&lt;p&gt;The white background can be achieved using &lt;code&gt;theme_minimal()&lt;/code&gt;, and removing all of the grid lines other than the major-x ones cleans up the look of the chart.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(p &amp;lt;- p +
  theme_minimal()  +
  theme(panel.grid.minor.x = element_blank(),
        panel.grid.major.y = element_blank()))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ggplotredo1/geographic-growth-midwest_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;step-4-change-font-and-convert-axis-to&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 4: Change Font and Convert Axis to %&lt;/h2&gt;
&lt;p&gt;Taken together, using a lighter color for the axis text and bolding the labels, make the chart look more professional. It’s so easy to rely on ggplot2’s default font choices that it’s also easy to forget that changing them can give your chart a completely different look. In this step, I also expressed the axis as percents, which is more consistent with how people think about growth (and happens to look better).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(p &amp;lt;- p +
  theme(plot.title = element_text(face = &amp;quot;bold&amp;quot;),
        plot.subtitle = element_text(face = &amp;quot;bold&amp;quot;),
        plot.caption = element_text(color = &amp;quot;gray53&amp;quot;, hjust = -.15,
                                    face = &amp;quot;bold&amp;quot;),
        axis.text.y = element_text(color = &amp;quot;gray30&amp;quot;, face = &amp;quot;bold&amp;quot;),
        axis.text.x = element_text(color = &amp;quot;gray30&amp;quot;, face = &amp;quot;bold&amp;quot;)) +
  scale_y_continuous(label = percent_format(), limits = c(0, .25))) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ggplotredo1/geographic-growth-midwest_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;step-5-add-an-icon&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 5: Add an Icon&lt;/h2&gt;
&lt;p&gt;The logo - which I added using the cowplot package - is functionally unnecessary but aesthetically powerful. It is the cilantro garnish on top of your beans and rice: Doesn’t add much flavor, but makes you all the more eager to dig in!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggdraw() +
  draw_image(&amp;quot;C:/Users/aspirgel/Desktop/ariespirgel/static/img/us-map.png&amp;quot;,
             y = .85,
             x = 0.1,
             width = .15,
             height = .15
           ) +
  draw_plot(p)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ggplotredo1/geographic-growth-midwest_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;ggplot2 has become so popular that I rarely, if ever, search online for a question about it that hasn’t already been asked and answered. This task was no different, with each question I had (e.g., how do I add an icon?) quickly resolved with a &lt;a href=&#34;https://stackoverflow.com/questions/9917049/inserting-an-image-to-ggplot2&#34;&gt;StackOverflow solution&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Small adjustments make a big difference, and the beauty of ggplot2 is that those adjustments are not only possible, but the knowledge to accomplish them is accessible (&lt;a href=&#34;https://community.rstudio.com/&#34;&gt;RStudio Community&lt;/a&gt;, &lt;a href=&#34;https://r4ds.had.co.nz/&#34;&gt;R for Data Science&lt;/a&gt;, etc.). Stay tuned for more tricks on how you can make your ggplots more interpretable, compelling, and visually satisfying!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>An example preprint / working paper</title>
      <link>/publication/preprint/</link>
      <pubDate>Sun, 07 Apr 2019 00:00:00 +0000</pubDate>
      <guid>/publication/preprint/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Slides&lt;/em&gt; button above to demo Academic&#39;s Markdown slides feature.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Supplementary notes can be added here, including &lt;a href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/&#34;&gt;code and math&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>/slides/example/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>/slides/example/</guid>
      <description>&lt;h1 id=&#34;create-slides-in-markdown-with-academic&#34;&gt;Create slides in Markdown with Academic&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://sourcethemes.com/academic/&#34;&gt;Academic&lt;/a&gt; | &lt;a href=&#34;https://sourcethemes.com/academic/docs/managing-content/#create-slides&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Efficiently write slides in Markdown&lt;/li&gt;
&lt;li&gt;3-in-1: Create, Present, and Publish your slides&lt;/li&gt;
&lt;li&gt;Supports speaker notes&lt;/li&gt;
&lt;li&gt;Mobile friendly slides&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Next: &lt;code&gt;Right Arrow&lt;/code&gt; or &lt;code&gt;Space&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Previous: &lt;code&gt;Left Arrow&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start: &lt;code&gt;Home&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Finish: &lt;code&gt;End&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overview: &lt;code&gt;Esc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Speaker notes: &lt;code&gt;S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fullscreen: &lt;code&gt;F&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Zoom: &lt;code&gt;Alt + Click&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hakimel/reveal.js#pdf-export&#34;&gt;PDF Export&lt;/a&gt;: &lt;code&gt;E&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;code-highlighting&#34;&gt;Code Highlighting&lt;/h2&gt;
&lt;p&gt;Inline code: &lt;code&gt;variable&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Code block:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;porridge = &amp;quot;blueberry&amp;quot;
if porridge == &amp;quot;blueberry&amp;quot;:
    print(&amp;quot;Eating...&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;In-line math: $x + y = z$&lt;/p&gt;
&lt;p&gt;Block math:&lt;/p&gt;
&lt;p&gt;$$
f\left( x \right) = ;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;fragments&#34;&gt;Fragments&lt;/h2&gt;
&lt;p&gt;Make content appear incrementally&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{% fragment %}} One {{% /fragment %}}
{{% fragment %}} **Two** {{% /fragment %}}
{{% fragment %}} Three {{% /fragment %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press &lt;code&gt;Space&lt;/code&gt; to play!&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;fragment &#34; &gt;
One 
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
&lt;strong&gt;Two&lt;/strong&gt; 
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
Three 
&lt;/span&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;A fragment can accept two optional parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class&lt;/code&gt;: use a custom style (requires definition in custom CSS)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight&lt;/code&gt;: sets the order in which a fragment appears&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;speaker-notes&#34;&gt;Speaker Notes&lt;/h2&gt;
&lt;p&gt;Add speaker notes to your presentation&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{% speaker_note %}}
- Only the speaker can read these notes
- Press `S` key to view
{{% /speaker_note %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press the &lt;code&gt;S&lt;/code&gt; key to view the speaker notes!&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Only the speaker can read these notes&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;
&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;black: Black background, white text, blue links (default)&lt;/li&gt;
&lt;li&gt;white: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;league: Gray background, white text, blue links&lt;/li&gt;
&lt;li&gt;beige: Beige background, dark text, brown links&lt;/li&gt;
&lt;li&gt;sky: Blue background, thin dark text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;night: Black background, thick white text, orange links&lt;/li&gt;
&lt;li&gt;serif: Cappuccino background, gray text, brown links&lt;/li&gt;
&lt;li&gt;simple: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;solarized: Cream-colored background, dark green text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;

&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/img/boards.jpg&#34;
  &gt;

&lt;h2 id=&#34;custom-slide&#34;&gt;Custom Slide&lt;/h2&gt;
&lt;p&gt;Customize the slide style and background&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{&amp;lt; slide background-image=&amp;quot;/img/boards.jpg&amp;quot; &amp;gt;}}
{{&amp;lt; slide background-color=&amp;quot;#0000FF&amp;quot; &amp;gt;}}
{{&amp;lt; slide class=&amp;quot;my-style&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;custom-css-example&#34;&gt;Custom CSS Example&lt;/h2&gt;
&lt;p&gt;Let&#39;s make headers navy colored.&lt;/p&gt;
&lt;p&gt;Create &lt;code&gt;assets/css/reveal_custom.css&lt;/code&gt; with:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.reveal section h1,
.reveal section h2,
.reveal section h3 {
  color: navy;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://spectrum.chat/academic&#34;&gt;Ask&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://sourcethemes.com/academic/docs/managing-content/#create-slides&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Brief History of NBA Three-Point Attempts: 1998 to 2018 Seasons</title>
      <link>/post/history-3s/history-of-basketball/</link>
      <pubDate>Thu, 24 Jan 2019 00:00:00 +0000</pubDate>
      <guid>/post/history-3s/history-of-basketball/</guid>
      <description>


&lt;p&gt;On October 29, 2018, in a game against the Chicago Bulls, Klay Thompson attempted 24 three-pointers, making 14 of them; both marks set NBA records. A couple months after that his teammate Stephen Curry attempted 14 three pointers in a single &lt;em&gt;half&lt;/em&gt; of a single NBA game, which tied an NBA record. That same game, the Golden State Warriors and Sacramento Kings made a combined 41 threes, a total that had never been reached before. Just this morning when I checked ESPN.com I learned that the previous night James Harden scored 61 points in Madison Square Garden, but maybe more shocking, he did it while attempting 20 three-point shots (he only made five of them).&lt;/p&gt;
&lt;p&gt;For anyone who has been paying attention to the NBA for more than a few years, these numbers look like typos. The NBA began using the three-point line in 1979, and on October 12 of that year - almost 40 years ago - &lt;a href=&#34;https://en.wikipedia.org/wiki/Three-point_field_goal#/media/File:Houston_Rockets_at_Boston_Celtics_1979-10-12_(Official_Scorer%27s_Report-Original)_(Chris_Ford_crop).jpg&#34;&gt;Chris Ford made the first one&lt;/a&gt;. For most of its history the three-point shot has been like that kitchen gadget you’ve always had but rarely used until someone showed you what a powerful tool it could be (immersion blender maybe?).&lt;/p&gt;
&lt;p&gt;In the case of the NBA, that &lt;em&gt;someone&lt;/em&gt; would be Houston Rockets General Manager Daryl Morey, who wisely drew attention to math and the reality that three is worth more than two. More specifically, his insight was that the shots most worth taking are higher percentage attempts near the basket (layups and dunks, ideally), or lower percentage ones that are further from the basket but are worth three points (free throws are also an important part of the equation in so-called Morey-Ball). This means that if a team’s goal is to get the most points out of every position (and that is every team’s goal), mid-range shots should be discouraged: They are harder to make than layups and dunks and still worth only two points.&lt;/p&gt;
&lt;p&gt;This has had a profound effect on how games are played and which players are valued. It wasn’t long ago that big men were expected to be able to post up near the basket and wouldn’t have to think about life outside the three-point arc. In 2019, a few games past the midpoint of the current season, Brook Lopez has already attempted 304 threes, Karl-Anthony Towns attempted 217, Marc Gasol attempted 193, Joel Embid attempted 178. Each of these players is listed as a center and is at least 7’0 feet tall. And the list goes on.&lt;/p&gt;
&lt;p&gt;And it’s not just who is shooting threes, it’s how they’re being shot. James Harden is setting new records for the number of &lt;a href=&#34;https://www.theringer.com/nba/2019/1/23/18193249/james-harden-scoring-history-houston-rockets&#34;&gt;unassisted threes made&lt;/a&gt;, meaning he doesn’t just shoot from deep as a compromise when better shots are not available, but it’s as if any shot that is &lt;em&gt;not&lt;/em&gt; a three is a compromise. Or consider Curry, for whom the three-point line itself is merely a suggestion; he has made &lt;a href=&#34;http://www.espn.com/nba/story/_/id/25771897/steph-curry-unleashing-impossible-range&#34;&gt;45 of 94 threes (47.9%!) launched from between 30 and 35 feet since 2014-2015&lt;/a&gt; (the line is 23 ft 9 inches from the basket, and 22 feet if you are standing in the corner).&lt;/p&gt;
&lt;p&gt;In 2019, you don’t have to watch games closely to notice the abundance of three pointers that are being shot. But still, I wanted to attach some numbers to the obvious, so below, I present a brief quantitative history of NBA three-point attempts.&lt;/p&gt;
&lt;div id=&#34;percentage-of-all-shot-attempts-that-were-threes&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Percentage of All Shot Attempts That Were Threes&lt;/h1&gt;
&lt;p&gt;It’s easy to forget how recent the explosion in three-point attempts has been. The chart below, which displays the percentage of all shot attempts that were threes, shows a gradual increase from 1998 to 2007. But from 2008 until 2012, the numbers leveled off, and it seemed peak-three had been reached. Then 2014 to 2018 happened, and the increase during that time period alone (7.77%) was greater than it was from all of 1998 to 2012 (6.65%)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/history-3s/history-of-basketball_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Although it’s a bit of an aside, despite the increase in the number of attempts, the percentage of three-pointers that have been made has remained relatively steady, as displayed below.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/history-3s/history-of-basketball_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;distribution-of-threes&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Distribution of Threes&lt;/h1&gt;
&lt;p&gt;As I mentioned above, three-point shots are no longer limited to certain positions, a point that is reflected in the histogram below. It shows players’ average number of three-point attempts per game along the x-axis, and the number of players falling within that range for the season is represented along the y-axis. Over time, notice how the distribution gets flatter. In 1998, the group who shot between zero and 0.5 threes per game appeared with the most frequency. But by 2018 that bar dropped significantly and the other bars lifted up. And pay attention to right side of the chart beginning in 2016.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/history-3s/history-of-basketball_files/figure-html/unnamed-chunk-4-1.gif&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;top-attempters-by-year&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Top Attempters by Year&lt;/h1&gt;
&lt;p&gt;Who are these gunners that are changing how basketball is played? The chart below displays the three players who averaged the most threes per game for each season from 1998 to 2018. Even the casual fan will not be surprised by the more recent appearances on the chart: Splash-Brothers Curry and Thompson; and Gordon and Harden, whose GM is the aforementioned Daryl Morey.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/history-3s/history-of-basketball_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;curry-explains-it-all&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Curry Explains it All&lt;/h1&gt;
&lt;p&gt;Daryl Morey’s influence on the game and the state of the evolution of the three-point shot is encapsulated by the shot charts below, which I downloaded using &lt;a href=&#34;https://github.com/toddwschneider/ballr&#34;&gt;Todd Schneider’s ballr package&lt;/a&gt;. The chart on the left is Stephen Curry’s shot chart from his 2009-2010 rookie season, and the shot chart on the right is from his 2017-2018 season. It’s almost as if during that time the in-between game disappeared, leaving only three point shots and shots at the basket. That, folks, is modern basketball.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/stephen-curry-2018-19-shot-chart-heat-map.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;The new style of play is not for everyone. Like any trend, this one can’t go on forever, but I do wonder how far it can go until it reaches a breaking point. Maybe the breaking point comes from the league if they decide to move the line &lt;a href=&#34;http://www.espn.com/blog/statsinfo/post/_/id/115055/what-moving-the-3-point-line-back-would-mean-for-warriors-nba&#34;&gt;further back&lt;/a&gt; or establish a &lt;a href=&#34;https://slate.com/culture/2016/06/the-4-point-line-could-be-coming-to-the-nba-heres-where-to-put-it.html&#34;&gt;four-point line&lt;/a&gt;. Or maybe it comes from the next Daryl Morey who discovers an inefficiency in the way the game is currently played. Either way, enjoy the show, because there is nothing quite like watching Stephen Curry casually make game winning shots from close to &lt;a href=&#34;https://www.youtube.com/watch?v=9dheZHuPSAo&#34;&gt;half court&lt;/a&gt;!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>About / Contact</title>
      <link>/contact/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>/contact/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Talks &amp; Workshops</title>
      <link>/talks/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>/talks/</guid>
      <description></description>
    </item>
    
    <item>
      <title>An Analysis of Gender Disparity Among Higher Education Chief Administrators</title>
      <link>/post/gender-college-presidents/gender-college-presidents/</link>
      <pubDate>Fri, 24 Aug 2018 00:00:00 +0000</pubDate>
      <guid>/post/gender-college-presidents/gender-college-presidents/</guid>
      <description>


&lt;p&gt;The chief administrator job of a higher education institution is, as the title implies, the pinnacle of careers in academic administration. The chief administrator is a school’s spokesperson and guides its vision, affecting the lives of the thousands of students who pass through those institutions. And for the chief administrators who don’t care about the idealism of educating future generations, I would imagine the &lt;a href=&#34;https://www.chronicle.com/interactives/executive-compensation#id=table_public_2017&#34;&gt;high-six/low-seven figure salaries&lt;/a&gt; that many earn is incentive enough. Despite the prominent roles that these administrators fill, there is a dearth of publicly available data on them.&lt;/p&gt;
&lt;p&gt;Every institution that participates in federal student financial aid is required to submit data to Integrated Postsecondary Education System, or IPEDS. Eventually, the submitted data is made publicly available in the &lt;a href=&#34;https://nces.ed.gov/ipeds/use-the-data&#34;&gt;IPEDS Data Center&lt;/a&gt;. This includes numbers on admissions, student enrollment, degree completions, graduation rates, financial aid, finances, human resources, and libraries. Much of this data has to be reported by gender and race/ethnicity. For example, how many Hispanic female undergraduates began at an institution last fall? What is the graduation rate of male American Indian Alaska Natives? What is the average salary of female instructional staff on a 9-month contract? But for one reason or another, as far as I can tell, the only things that must be reported about an institution’s chief administrator are her or his name and title.&lt;/p&gt;
&lt;p&gt;Names, though, are not completely devoid of meaningful information. If you live in the United States and hear the name Steven, you probably think of a male, and if you hear the name Mary, you probably think of a female. Yes, some names are more ambiguous than others (my own being a good example), and some people’s names might belie the gender they identify with, but there is a degree of reliability that a person’s name offers in determining whether they are female or male. Thus, using first names to make educated guesses about chief administrators’ gender, my goal here was to describe gender representation among this set of individuals.&lt;/p&gt;
&lt;p&gt;The first step was to download the names of the chief administrators for every institution in the IPEDS Data Center (n = 7108) and clean up the data. This required putting years in a consistent format; removing titles preceding first names (e.g., Dr., Ms., Mrs.); extracting first names into their own column; and adding variable labels for college sector.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(babynames)
library(scales)

admin &amp;lt;- read_csv(&amp;quot;data/chief-admin-names.csv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# tidy year 
admin &amp;lt;- admin %&amp;gt;% 
  gather(&amp;quot;year&amp;quot;, &amp;quot;name&amp;quot;, `Name of chief administrator (HD2016)`,
         `Name of chief administrator (HD2015)`:`Name of Chief Administrator (IC90HD)`) 

# extract year from names and put in consistent format
admin &amp;lt;- admin %&amp;gt;% 
  mutate(year =  parse_number(year),
         year = ifelse(year &amp;gt;= 9596 &amp;amp; year &amp;lt;= 9798,
                       str_sub(start = 1, end = 2, year), year),
         year = ifelse(nchar(year) == 2, 
                       paste0(&amp;quot;19&amp;quot;, year), 
                       year),
         year = as.integer(year))

# select and rename variables
admin &amp;lt;- admin %&amp;gt;% 
  select(unit_id = UnitID, 
         sector_code = `Sector of institution (HD2016)`,
         institution_name = `Institution Name`,
         year, name,
         undergrad_enroll_2016 = `Grand total (EF2016  All students  Undergraduate total)`,
         grad_enroll_2016 = `Grand total (EF2016  All students  Graduate and First professional)`)

# titles are in the first position for many names, so need to remove
# those so can extract first posistion from names and have it reflect
# first name
admin &amp;lt;- admin %&amp;gt;% 
  mutate(name = tolower(name),
         name = gsub(&amp;quot;\\.&amp;quot;, &amp;quot;&amp;quot;, name),
         name = gsub(&amp;quot;\\&amp;lt;dr\\&amp;gt;&amp;quot;, &amp;quot;&amp;quot;, name),
         name = gsub(&amp;quot;\\&amp;lt;mr\\&amp;gt;&amp;quot;, &amp;quot;&amp;quot;, name),
         name = gsub(&amp;quot;\\&amp;lt;ms\\&amp;gt;&amp;quot;, &amp;quot;&amp;quot;, name),
         name = gsub(&amp;quot;\\&amp;lt;mrs\\&amp;gt;&amp;quot;, &amp;quot;&amp;quot;, name),
         name = gsub(&amp;quot;\\&amp;lt;rev\\&amp;gt;&amp;quot;, &amp;quot;&amp;quot;, name),
         name = gsub(&amp;quot;\\&amp;lt;reverend\\&amp;gt;&amp;quot;, &amp;quot;&amp;quot;, name),
         name = gsub(&amp;quot;\\&amp;lt;very reverend\\&amp;gt;&amp;quot;, &amp;quot;&amp;quot;, name),
         name = gsub(&amp;quot;\\&amp;lt;very\\&amp;gt;&amp;quot;, &amp;quot;&amp;quot;, name),
         name = gsub(&amp;quot;\\&amp;lt;rabbi\\&amp;gt;&amp;quot;, &amp;quot;&amp;quot;, name),
         name = gsub(&amp;quot;\\&amp;lt;msgr\\&amp;gt;&amp;quot;, &amp;quot;&amp;quot;, name),
         name = gsub(&amp;quot;\\&amp;lt;dra\\&amp;gt;&amp;quot;, &amp;quot;&amp;quot;, name),
         name = gsub(&amp;quot;\\&amp;lt;sr\\&amp;gt;&amp;quot;, &amp;quot;&amp;quot;, name),
         name = str_trim(name, side = &amp;quot;both&amp;quot;),
         full_name = tolower(name)) %&amp;gt;% 
  separate(name, into = &amp;quot;first_name&amp;quot;, sep = &amp;quot; &amp;quot;)

# add sector label
labels &amp;lt;- read_csv(&amp;quot;data/sector-value-labels.csv&amp;quot;) %&amp;gt;% 
  select(sector_code = Value, 
         sector_label = ValueLabel)

admin &amp;lt;- left_join(admin, labels, by = &amp;quot;sector_code&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, I assigned a gender to each chief administrator based on her or his first name. To do this, I used R’s &lt;code&gt;babynames&lt;/code&gt; package, which contains the number of babies born every year from 1880 to 2015 for each combination of name and sex&lt;a href=&#34;#fn1&#34; class=&#34;footnoteRef&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;. I took the babynames data and calculated how often each name was given to females vs. males, and then assigned gender based on the higher proportion. For example, in the babynames data, about 72% of all newborns named Jaydin were male, so I assigned the name Jaydin to male. Names like Jaydin, however, were the exception: Most of the time, names went overwhelmingly to one sex or the other, with the vast majority of names in the babynames dataset being associated with only one sex.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# read in babynames data and assign a proportion to female and male for each name
baby_names &amp;lt;- babynames %&amp;gt;% 
  select(sex, name, n) %&amp;gt;% 
  mutate(name = tolower(name))

baby_names &amp;lt;- baby_names %&amp;gt;% 
  group_by(sex, name) %&amp;gt;% 
  summarise(total = sum(n)) %&amp;gt;% 
  ungroup() %&amp;gt;% 
  group_by(name) %&amp;gt;% 
  mutate(prop = total/sum(total)) %&amp;gt;%
  filter(prop == max(prop)) %&amp;gt;% 
  ungroup() %&amp;gt;% 
  select(sex, first_name = name, prop)

# one chief admin officer has name gold and it happens to be one that is .5 prop,
# so removed from dataset. (gold was given as full name, so i&amp;#39;m *guessing* this 
# is actually last name).
baby_names &amp;lt;- baby_names %&amp;gt;% 
  filter(first_name != &amp;quot;gold&amp;quot; | prop != .5)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;historical-trends&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Historical Trends&lt;/h1&gt;
&lt;p&gt;This gave me a “dictionary” containing the probabilistic sex of 97,430 first names, which I then linked to the chief administrator data&lt;a href=&#34;#fn2&#34; class=&#34;footnoteRef&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;, making it possible to examine historical trends in gender differences among chief administrators. (The babynames data is based on sex, but once I link it to adults’ names (i.e., the administrators), I make the (often wrong) assumption that names reflect gender. Also, of course, with this data, it is not possible to account for gender non-binary administrators).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# join ipeds and babynames, removing rows where there were no matches
admin &amp;lt;- left_join(admin, baby_names, by = &amp;quot;first_name&amp;quot;) %&amp;gt;% 
  mutate(institution_name = gsub(&amp;quot;-&amp;quot;, &amp;quot; &amp;quot;, institution_name)) %&amp;gt;% 
  filter(!is.na(sex))

admin &amp;lt;- admin %&amp;gt;% 
  select(unit_id, institution_name, sector_label, year, undergrad_enroll_2016, 
         grad_enroll_2016, full_name, first_name, sex)

# several variables are for 2016 only, so put those in their own data frame
admin_2016 &amp;lt;- admin %&amp;gt;% 
  filter(year == 2016) %&amp;gt;% 
  select(-year)

admin &amp;lt;- admin %&amp;gt;% 
  select(-undergrad_enroll_2016, -grad_enroll_2016)

# proportion female by year
female_prop_sex &amp;lt;- admin %&amp;gt;% 
  count(year, sex) %&amp;gt;%
  group_by(year) %&amp;gt;% 
  mutate(year_total = sum(n)) %&amp;gt;% 
  ungroup() %&amp;gt;% 
  mutate(prop_sex = n/year_total) %&amp;gt;% 
  filter(sex == &amp;quot;F&amp;quot;)
  
female_prop_sex %&amp;gt;% 
  ggplot(aes(x = factor(year), y = prop_sex, group = 1)) +
  geom_line() +
  geom_point() +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  scale_y_continuous(label = percent_format()) +
  labs(x = &amp;quot;Year&amp;quot;, y = &amp;quot;Percent Women&amp;quot;,
       title = &amp;quot;Percentage of Chief Administrators Who Are Women&amp;quot;,
       subtitle = &amp;quot;All IPEDS Institutions, Years 1990-2016&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/gender-college-presidents/gender-college-presidents_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There are three things to notice about the chart:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;The increasing percentage of chief administrators who are women&lt;a href=&#34;#fn3&#34; class=&#34;footnoteRef&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;The still minority percentage of chief administrators who are women&lt;/li&gt;
&lt;li&gt;The 35% figure I came up with for 2016 is roughly consistent with a &lt;a href=&#34;http://www.acenet.edu/news-room/Documents/Leading-the-Way-to-Parity.pdf&#34;&gt;survey reporting that 30%&lt;/a&gt; of 2016 college presidents were women), and compatible with the trends reported &lt;a href=&#34;https://infogram.com/ready-to-lead-women-in-the-presidency-1h8n6me9o9392xo&#34;&gt;here&lt;/a&gt;, lending some support to the approach I selected.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;institution-type&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Institution Type&lt;/h1&gt;
&lt;p&gt;&lt;em&gt;School&lt;/em&gt;, as it’s used in IPEDS, is a broad term that covers vastly different types of institutions. It includes everything from a cosmetology school that enrolls a handful of students each year to flagship schools with billion-plus endowments and tens of thousands of students. That is to say, chief administrator positions vary in prestige, responsibility, salary, and a host of other intangibles. With that in mind, I calculated the percentage of female chief administrators, by sector.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# proportion female by sector
female_by_sector &amp;lt;- admin_2016 %&amp;gt;% 
  count(sector_label, sex) %&amp;gt;% 
  group_by(sector_label) %&amp;gt;% 
  mutate(prop_sex = n/sum(n)) %&amp;gt;% 
  ungroup() %&amp;gt;% 
  filter(sex == &amp;quot;F&amp;quot;)

female_by_sector %&amp;gt;%
  ggplot(aes(x = reorder(sector_label, prop_sex), y = prop_sex)) +
  geom_col() +
  coord_flip() +
  scale_y_continuous(label = percent_format()) +
  theme_minimal() +
  labs(x = NULL, y = &amp;quot;Percent Women&amp;quot;,
       title = &amp;quot;Percentage of Chief Aministrators Who Are Women,\nby Sector&amp;quot;,
       subtitle = &amp;quot;All IPEDS Institutions, Year 2016&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/gender-college-presidents/gender-college-presidents_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Although they are a minority in every sector, women make up a higher percentage of chief administrators at 2-year schools than at 4-year schools. One institution type is not better than another, but they serve different functions (e.g., teaching vs. research), meaning the disparities by sector further exaggerate the existing imbalance. For example, in 2016, 35.0% of academic chief administrators were women, yet the institutions they led accounted for only 28.5% of all students enrolled at institutions of higher education.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;The overall trend is moving in the right direction, but change is slow: From 1990 to 2016, the average yearly increase in the percentage of women chief administrators was 0.653%. These are prestigious jobs that aren’t vacated haphazardly, so for the near-term, the disparity is here to stay: If the same rate of change observed from 1990 to 2016 continues, it will take 23 years until gender parity among chief administrators is achieved.&lt;/p&gt;
&lt;p&gt;This is of course not a problem unique to higher education, but a societal one that begins well before women submit job applications. We must be aware of our biases - stop always telling your niece that she is pretty and her brother that he is smart! - however subtle they are, and correct them. You don’t have to be a woman to care about this, after all, “&lt;a href=&#34;https://www.pbs.org/weta/washingtonweek/web-video/hillary-clinton-declares-womens-rights-are-human-rights&#34;&gt;human rights are women’s rights&lt;/a&gt;”.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;The data is restricted to combinations of five for more.&lt;a href=&#34;#fnref1&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;I removed rows where there were no matches between first names in the IPEDS data and first names in the babynames data.&lt;a href=&#34;#fnref2&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;You may have noticed a slight dip from 2006 to 2009. Considering how abrupt it is, I’m skeptical it represents a real trend. My guess is that it is instead reflective of an unrelated change in the underlying data (e.g., different reporting requirements), but I’m not entirely sure.&lt;a href=&#34;#fnref3&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Popularity of Various Data Analytic Tools at AIR Forums</title>
      <link>/post/air-forum-text-software-frequency/air-forum-text-software-frequency/</link>
      <pubDate>Fri, 24 Aug 2018 00:00:00 +0000</pubDate>
      <guid>/post/air-forum-text-software-frequency/air-forum-text-software-frequency/</guid>
      <description>


&lt;p&gt;Data: It’s become a cliche to say that it’s everywhere and in quantities that are unimaginable. But data in its raw form, whether in a structured database or on the internet, is of limited use until a human does something to it: Gather it, clean it, visualize it, model it, write about it, and so-on.&lt;/p&gt;
&lt;p&gt;The amount of data that those in institutional research encounter requires powerful tools to work with. And those tools exist. Lots of them. Everything from free, open-source software, to software costing hundreds of thousands dollars offered by companies that won’t stop emailing you despite unsubscribing from their list on a weekly basis.&lt;/p&gt;
&lt;p&gt;On the rare occasion someone asks me which software I’d recommend, I always say R. In my experience, its ability to do everything you’d want and need to do as an institutional researcher is unmatched (cut to five minutes later when that someone regrets having asked me and is looking for ways to exit the conversation). But rather than use this space to drone on about why I think R is amazing, my goal here is to reveal the software preferences of others in the field. (And obviously, I used R to do this!)&lt;/p&gt;
&lt;p&gt;It’s not a perfect approach, but my thinking was I could see how often different tools were mentioned in AIR Forum program books and how that’s changed over time. My first step was to download the program books from the forum website going back six years. Next, I created a function to read each of the programs books into R and &lt;a href=&#34;https://www.tidyverse.org/&#34;&gt;tidy&lt;/a&gt; them so every individual word within each book is contained on its own line in a single data frame.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# load packages
library(pdftools)
library(tidyverse)
library(tidytext)
library(scales)

# function to read in PDFs and get one word per line.
text_prepr &amp;lt;- function(doc, forum_year){
  
  reg &amp;lt;- &amp;quot;([^A-Za-z\\d#@&amp;#39;]|&amp;#39;(?![A-Za-z\\d#@]))&amp;quot;
  
  df &amp;lt;- pdf_text(doc)
  
  df &amp;lt;- data.frame(df)

  df &amp;lt;- df %&amp;gt;%
    rename(text = df) %&amp;gt;%
    unnest_tokens(word, text,  token = &amp;quot;regex&amp;quot;, pattern = reg) %&amp;gt;%
    mutate(year = forum_year)
  
  return(df)
}

# apply function to programs books
all_years &amp;lt;- bind_rows(
  text_prepr(&amp;quot;data/AIR-2018-Forum-Program-Book.pdf&amp;quot;, 2018),
  text_prepr(&amp;quot;data/2017-AIR-Forum-Program-Book.pdf&amp;quot;, 2017),
  text_prepr(&amp;quot;data/2016_AIR-Forum_Program-Book.pdf&amp;quot;, 2016),
  text_prepr(&amp;quot;data/2015-Forum-Program-Book-Web.pdf&amp;quot;, 2015),
  text_prepr(&amp;quot;data/2014ForumProgramBookFinal.pdf&amp;quot;, 2014),
  text_prepr(&amp;quot;data/2013finalprogram.pdf&amp;quot;, 2013)
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This resulted in a data frame with a total 447583 rows (one row for each word), a glimpse of which is printed below:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(all_years)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            word year
## 1   association 2018
## 2           for 2018
## 3 institutional 2018
## 4      research 2018
## 5          2018 2018
## 6           may 2018&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, I decided on which words I would ask R to look for. Somewhat arbitrarily and somewhat based on my experience at AIR Forums, I chose the following: &lt;em&gt;Excel&lt;/em&gt;, &lt;em&gt;R&lt;/em&gt;, &lt;em&gt;SAS&lt;/em&gt;, &lt;em&gt;SPSS&lt;/em&gt;, and &lt;em&gt;Tableau&lt;/em&gt;. The code below (1) searches for mentions of those tools in the list of words created above (2) counts the results by year (3) builds a chart of the results. To clarify, the resulting chart displays the number of times each software is mentioned in each of the AIR Forum program books for each of the respective years.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# filter for keywords and count by word and year
software &amp;lt;- all_years %&amp;gt;% 
  mutate(word = tolower(word)) %&amp;gt;% 
  filter(word %in% c(&amp;quot;excel&amp;quot;, &amp;quot;r&amp;quot;, &amp;quot;sas&amp;quot;, &amp;quot;spss&amp;quot;, &amp;quot;tableau&amp;quot;)) %&amp;gt;% 
  count(word, year) %&amp;gt;% 
  complete(word, year, fill = list(n = 0))

# make data frame of only 2018, so can include as labels at end of lines
software_2018 &amp;lt;- software %&amp;gt;% 
  filter(year == 2018)

# create chart
ggplot() +
  geom_line(data = software, aes(x = year, y = n, color = word, group = word), size = 2) +
  geom_text(data = software_2018, aes(x = year, y = n, label = word), nudge_y = 2) +
  geom_point(data = software, aes(x = year, y = n, color = word), size = 3) +
  theme_minimal() +
  labs(x = &amp;quot;Forum Year&amp;quot;, y = &amp;quot;# of Mentions&amp;quot;,
       title = &amp;quot;Number of Times Software is Mentioned in AIR Forum Program Book&amp;quot;,
       subtitle = &amp;quot;2013 to 2018 Forums&amp;quot;) +
  guides(color = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/air-forum-text-software-frequency/air-forum-text-software-frequency_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;What stands out - and confirms what I’ve noticed at AIR Forums - is the rapid rise of Tableau. In 2014 I had never heard of it. In 2018, not knowing at least something about it seems unavoidable. Tableau is known for visual analytics, so it’s not surprising that its rise in populairty has coincided with an increasing interest in data visualization at AIR Forums.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# filter for keyword and count by word and year
visualize &amp;lt;- all_years %&amp;gt;% 
  group_by(year) %&amp;gt;% 
  mutate(total = n()) %&amp;gt;% 
  ungroup() %&amp;gt;% 
  mutate(visualiz = str_detect(word, &amp;quot;visualiz&amp;quot;)) %&amp;gt;%
  group_by(year) %&amp;gt;% 
  summarise(prop = mean(visualiz)) %&amp;gt;% 
  ungroup()


# create chart
ggplot(visualize, aes(x = year, y = prop)) +
  geom_line(size = 2) +
  geom_point(size = 3) +
  theme_minimal() +
  labs(x = &amp;quot;Forum Year&amp;quot;, y = &amp;quot;% of Mentions&amp;quot;,
       title = &amp;#39;Percent of All Words That Were &amp;quot;Visualiz*&amp;quot; in AIR Forum Program Book&amp;#39;,
       subtitle = &amp;quot;2013 to 2018 Forums&amp;quot;) +
  guides(color = FALSE) +
  scale_y_continuous(label = percent_format())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/air-forum-text-software-frequency/air-forum-text-software-frequency_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Returning to the first chart, perhaps it’s my background in psychology - a field which has historically been dominated by SPSS - but I was surprised how little SPSS is mentioned (although, I wouldn’t be surprised to see it decrease in the future). As for R, it seems to have a presence, but I’m curious to see what happens to its popularity in institutional research over the next few years. Judging by my experience at recent Forums and the development of R tools that decrease the barrier to entry, my prediction is that interest will only grow.&lt;/p&gt;
&lt;p&gt;I’m not sure if this need be said, but I will: This approach to evaluating software popularity is fraught with limitations. My goal, however, was not to get a precise estimate. Rather, I was interested in one, getting a general sense of broad trends, and two, sharing how just a little of bit R code can do so much!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Privacy Policy</title>
      <link>/privacy/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0100</pubDate>
      <guid>/privacy/</guid>
      <description>&lt;p&gt;&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Terms</title>
      <link>/terms/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0100</pubDate>
      <guid>/terms/</guid>
      <description>&lt;p&gt;&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Achieving Reproducibility in IR With R</title>
      <link>/talk/2018-air/</link>
      <pubDate>Thu, 31 May 2018 10:45:00 +0000</pubDate>
      <guid>/talk/2018-air/</guid>
      <description>


&lt;p&gt;Although the concept of reproducibility is typically reserved for the sciences, the presenter will argue that by adopting its principles, IR offices would see immeasurable benefits in efficiency, accuracy, and transparency. Reproducible workflows preserve every decision made about data analyses (e.g., removing a student who withdrew) and allow users to quickly and accurately respond to requests for modifications (e.g., group tables by college instead of major). One barrier to reproducibility, however, is that it requires coding. Using examples from the free R programming language, the presenter will show that not only is R an ideal software for reproducibility, but that many of its modern features are designed to get novices quickly doing powerful things. The primary goals of the presentation are for audience members to leave convinced that they can learn R, and that if they do, they will become better at their jobs.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Data Visualization Showcase</title>
      <link>/talk/2017-air/</link>
      <pubDate>Tue, 30 May 2017 15:30:00 +0000</pubDate>
      <guid>/talk/2017-air/</guid>
      <description>


&lt;p&gt;A multitude of tools and promising practices exist for visualizing data for informing and decision making. This session will feature a showcase of tools and techniques for utilizing data to inform and present. Presenters were all provided the same dataset and guiding questions and each used a different tool (Excel, R, Tableau, and SAS Visual Analytics) to create a visual display of the data. Each will present their work with the session moderator highlighting best practice in visualization throughout the presentation.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Creating Data Visualizations Using R: An Introduction for Non-Programmers</title>
      <link>/talk/2016-air/</link>
      <pubDate>Fri, 01 Jul 2016 15:00:00 +0000</pubDate>
      <guid>/talk/2016-air/</guid>
      <description>


&lt;p&gt;Creating graphs is a central part of the IR workload, but it can be frustrating. If you make graphs using Excel, you might spend hours mindlessly pointing-and-clicking, which then has to be repeated if updates to the graphs are required. The presenter will begin by arguing in favor of two points: First, IR professionals would be better off using R (a free and open-source programming language), and second, even those without any programming experience can learn R well enough to reap its majesty. A demonstration will be given on how to create and modify a scatter plot using ggplot2, an R package for building highly customizable visualizations. The primary goal of the presentation is for audience members to leave feeling empowered to learn to use R to improve the quantity, quality, and reproducibility of their work&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>External Project</title>
      <link>/project/external-project/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>/project/external-project/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Internal Project</title>
      <link>/project/internal-project/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>/project/internal-project/</guid>
      <description>&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>An example journal article</title>
      <link>/publication/journal-article/</link>
      <pubDate>Tue, 01 Sep 2015 00:00:00 +0000</pubDate>
      <guid>/publication/journal-article/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Slides&lt;/em&gt; button above to demo Academic&#39;s Markdown slides feature.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Supplementary notes can be added here, including &lt;a href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/&#34;&gt;code and math&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>An example conference paper</title>
      <link>/publication/conference-paper/</link>
      <pubDate>Mon, 01 Jul 2013 00:00:00 +0000</pubDate>
      <guid>/publication/conference-paper/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Slides&lt;/em&gt; button above to demo Academic&#39;s Markdown slides feature.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Supplementary notes can be added here, including &lt;a href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/&#34;&gt;code and math&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
