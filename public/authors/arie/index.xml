<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>arie | Arie Spirgel</title>
    <link>/authors/arie/</link>
      <atom:link href="/authors/arie/index.xml" rel="self" type="application/rss+xml" />
    <description>arie</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Fri, 17 Jan 2020 11:00:00 +0000</lastBuildDate>
    <image>
      <url>/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>arie</title>
      <link>/authors/arie/</link>
    </image>
    
    <item>
      <title>Welcome to the Tidyverse: Part 2</title>
      <link>/talk/colorado-ed-part-2/</link>
      <pubDate>Fri, 17 Jan 2020 11:00:00 +0000</pubDate>
      <guid>/talk/colorado-ed-part-2/</guid>
      <description>


&lt;p&gt;Part 2 of “&lt;a href=&#34;https://github.com/rstudio-education/welcome-to-the-tidyverse&#34;&gt;Welcome to the Tidyverse&lt;/a&gt;”, which covers the following topics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Modeling with &lt;code&gt;modelr&lt;/code&gt; and &lt;code&gt;broom&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Reporting with &lt;code&gt;rmarkdown&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Welcome to the Tidyverse: Part 1</title>
      <link>/talk/colorado-ed-part-1/</link>
      <pubDate>Tue, 14 Jan 2020 11:00:00 +0000</pubDate>
      <guid>/talk/colorado-ed-part-1/</guid>
      <description>


&lt;p&gt;Part 1 of “&lt;a href=&#34;https://github.com/rstudio-education/welcome-to-the-tidyverse&#34;&gt;Welcome to the Tidyverse&lt;/a&gt;”, which covers the following topics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Introduction to R.&lt;/li&gt;
&lt;li&gt;Visualization with &lt;code&gt;ggplot2&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Tranformation with &lt;code&gt;dplyr&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>ggplot2: Going Beyond the Defaults</title>
      <link>/post/ggplotredo1/geographic-growth-midwest/</link>
      <pubDate>Sun, 05 Jan 2020 00:00:00 +0000</pubDate>
      <guid>/post/ggplotredo1/geographic-growth-midwest/</guid>
      <description>


&lt;p&gt;With ggplot2 - the ubiquitous tool for making plots in R - you can create beautiful data visualizations without doing much to the defaults. By applying the template below (see &lt;a href=&#34;https://r4ds.had.co.nz/&#34;&gt;R for Data Science&lt;/a&gt;), adding a theme (e.g., &lt;code&gt;theme_light()&lt;/code&gt;), and giving your chart custom labels, you can have a publication-ready visualization.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = &amp;lt;DATA&amp;gt;) + 
  &amp;lt;GEOM_FUNCTION&amp;gt;(
     mapping = aes(&amp;lt;MAPPINGS&amp;gt;),
     stat = &amp;lt;STAT&amp;gt;, 
     position = &amp;lt;POSITION&amp;gt;
  ) +
  &amp;lt;COORDINATE_FUNCTION&amp;gt; +
  &amp;lt;FACET_FUNCTION&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But the more I pay attention to how people respond to visualizations, the more I realize how minor improvements can make a major difference. Like cooking, where adding a little bit of salt or giving a dish a few extra minutes in the oven can transform a meal from acceptable to outstanding, relatively small changes to a chart can do the same.&lt;/p&gt;
&lt;p&gt;Take the example below, in which one of &lt;a href=&#34;http://stephanieevergreen.com/before-and-after-business-slides/&#34;&gt;Stephanie Evergreen’s&lt;/a&gt; clients started with the slide on the top, and she helped them create the one below it:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/evergreen-before.png&#34; width=&#34;400&#34; /&gt;&lt;img src=&#34;/img/evergreen-after.png&#34; width=&#34;400&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Both charts contain the same information, and even if you can’t express why, you just &lt;em&gt;know&lt;/em&gt; the one on the bottom is better. Continuing with the cooking analogy, the charts are like two Mexican restaurants that use the same ingredients, but at one, the guacamole is fresher, the rice is more flavorful, and the tortillas are made in house.&lt;/p&gt;
&lt;p&gt;ggplot2 was designed so users can &lt;a href=&#34;https://r4ds.had.co.nz/data-visualisation.html&#34;&gt;build any plot that they can imagine&lt;/a&gt;, so as attractive as its defaults are, my goal with this series of posts is to venture beyond the minor design adjustments I typically make and learn to tweak charts from ordinary to outstanding. My first goal was to use ggplot2 to reproduce the chart that Dr. Evergreen created for her client, which based on her post, I think she did in Excel.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(scales)
library(cowplot)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;step-0-create-the-dataset&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 0: Create the Dataset&lt;/h2&gt;
&lt;p&gt;In addition to creating the data set, I used &lt;code&gt;fct_reorder()&lt;/code&gt; so the bars will appear in order from highest to lowest growth in the chart.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;growth &amp;lt;- tribble(
  ~region,               ~growth, ~group,
  &amp;quot;Large city, Midwest&amp;quot;,     .2,   &amp;quot;Midwest&amp;quot;,
  &amp;quot;Large city, East Coast&amp;quot;, .175,   &amp;quot;Other&amp;quot;,
  &amp;quot;Medium city, South&amp;quot;,      .165,  &amp;quot;Other&amp;quot;,
  &amp;quot;Medium city, Midwest&amp;quot;,    .165,  &amp;quot;Midwest&amp;quot;,
  &amp;quot;Small city, Midwest&amp;quot;,     .14,   &amp;quot;Midwest&amp;quot;, 
  &amp;quot;Large city, West coast&amp;quot;,  .10,   &amp;quot;Other&amp;quot;
) %&amp;gt;% 
  mutate(region = fct_reorder(region, growth)) &lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;step-1-make-the-foundational-chart&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 1: Make the Foundational Chart&lt;/h2&gt;
&lt;p&gt;This chart contains all of the information that the final chart contains, but it’s like the decent restaurant you’ll never return to: fine, but unmemorable. In this step, I also narrowed the width of the bars, a subtle alteration that improves the feel of the chart as it gets closer to the finished product.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(p &amp;lt;- growth %&amp;gt;% 
  ggplot(aes(x = region, y = growth, fill = group)) + 
  geom_col(width = .7) + 
  coord_flip() + 
  labs(x = NULL, y = NULL, 
       title = &amp;quot;Geographic growth dominated by Midwest.&amp;quot;,
       subtitle = &amp;quot;5 year growth&amp;quot;,
       caption = &amp;quot;Source: Our Smart Source 2015&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ggplotredo1/geographic-growth-midwest_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;step-2-update-the-colors-and-remove-the-legend&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 2: Update the Colors and Remove the Legend&lt;/h2&gt;
&lt;p&gt;Even if you like the default ggplot2 colors - which I very much do - putting a dark color next to a muted color does a better job of highlighting a conclusion you might want to draw attention to. And by juxtaposing the green and gray, in combination with the chart’s title, the legend becomes extraneous and can be removed.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(p &amp;lt;- p +
  scale_fill_manual(values = c(&amp;quot;#4D643D&amp;quot;, &amp;quot;#D7DBDD&amp;quot;)) +
  guides(fill = FALSE))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ggplotredo1/geographic-growth-midwest_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;step-3-white-background-and-minimal-gridlines&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 3: White Background and Minimal Gridlines&lt;/h2&gt;
&lt;p&gt;The white background can be achieved using &lt;code&gt;theme_minimal()&lt;/code&gt;, and removing all of the grid lines other than the major-x ones cleans up the look of the chart.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(p &amp;lt;- p +
  theme_minimal()  +
  theme(panel.grid.minor.x = element_blank(),
        panel.grid.major.y = element_blank()))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ggplotredo1/geographic-growth-midwest_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;step-4-position-titles-change-font-and-convert-axis-to&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 4: Position Titles, Change Font, and Convert Axis to %&lt;/h2&gt;
&lt;p&gt;Taken together, moving the titles further to the left, using a lighter color for the axis text, and bolding the labels, make the chart look more professional. It’s so easy to rely on ggplot2’s default font choices that it’s also easy to forget that changing them can give your chart a completely different look. In this step, I also expressed the axis as percents, which is more consistent with how people think about growth (and happens to look better).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(p &amp;lt;- p +
  theme(plot.title = element_text(hjust = 4, face = &amp;quot;bold&amp;quot;),
        plot.subtitle = element_text(hjust = -.41, vjust = 3,
                                     face = &amp;quot;bold&amp;quot;),
        plot.caption = element_text(color = &amp;quot;gray53&amp;quot;, hjust = -.61,
                                    face = &amp;quot;bold&amp;quot;),
        axis.text.y = element_text(color = &amp;quot;gray30&amp;quot;, face = &amp;quot;bold&amp;quot;),
        axis.text.x = element_text(color = &amp;quot;gray30&amp;quot;, face = &amp;quot;bold&amp;quot;)) +
    scale_y_continuous(label = percent_format(), limits = c(0, .25))) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ggplotredo1/geographic-growth-midwest_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;step-5-add-an-icon&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 5: Add an Icon&lt;/h2&gt;
&lt;p&gt;The logo - which I added using the cowplot package - is functionally unnecessary but aesthetically powerful. It is the cilantro garnish on top of your beans and rice: Doesn’t add much flavor, but makes you all the more eager to dig in!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggdraw() +
  draw_image(&amp;quot;us-map.png&amp;quot;,
             y = 0.90,
             width = .09, 
             height = .09
           ) +
  draw_plot(p)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Package `magick` is required to draw images. Image not drawn.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ggplotredo1/geographic-growth-midwest_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;ggplot2 has become so popular that I rarely, if ever, search online for a question about it that hasn’t already been asked and answered. This task was no different, with each question I had (e.g., how do I add an icon?) quickly resolved with a &lt;a href=&#34;https://stackoverflow.com/questions/9917049/inserting-an-image-to-ggplot2&#34;&gt;StackOverflow solution&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Small adjustments make a big difference, and the beauty of ggplot2 is that those adjustments are not only possible, but the knowledge to accomplish them is accessible (&lt;a href=&#34;https://community.rstudio.com/&#34;&gt;RStudio Community&lt;/a&gt;, &lt;a href=&#34;https://r4ds.had.co.nz/&#34;&gt;R for Data Science&lt;/a&gt;, etc.). Stay tuned for more tricks on how you can make your ggplots more interpretable, compelling, and visually satisfying!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>A Brief History of NBA Three-Point Attempts: 1998 to 2018 Seasons</title>
      <link>/post/history-3s/history-of-basketball/</link>
      <pubDate>Thu, 24 Jan 2019 00:00:00 +0000</pubDate>
      <guid>/post/history-3s/history-of-basketball/</guid>
      <description>


&lt;p&gt;On October 29, 2018, in a game against the Chicago Bulls, Klay Thompson attempted 24 three-pointers, making 14 of them; both marks set NBA records. A couple months after that his teammate Stephen Curry attempted 14 three pointers in a single &lt;em&gt;half&lt;/em&gt; of a single NBA game, which tied an NBA record. That same game, the Golden State Warriors and Sacramento Kings made a combined 41 threes, a total that had never been reached before. Just this morning when I checked ESPN.com I learned that the previous night James Harden scored 61 points in Madison Square Garden, but maybe more shocking, he did it while attempting 20 three-point shots (he only made five of them).&lt;/p&gt;
&lt;p&gt;For anyone who has been paying attention to the NBA for more than a few years, these numbers look like typos. The NBA began using the three-point line in 1979, and on October 12 of that year - almost 40 years ago - &lt;a href=&#34;https://en.wikipedia.org/wiki/Three-point_field_goal#/media/File:Houston_Rockets_at_Boston_Celtics_1979-10-12_(Official_Scorer%27s_Report-Original)_(Chris_Ford_crop).jpg&#34;&gt;Chris Ford made the first one&lt;/a&gt;. For most of its history the three-point shot has been like that kitchen gadget you’ve always had but rarely used until someone showed you what a powerful tool it could be (immersion blender maybe?).&lt;/p&gt;
&lt;p&gt;In the case of the NBA, that &lt;em&gt;someone&lt;/em&gt; would be Houston Rockets General Manager Daryl Morey, who wisely drew attention to math and the reality that three is worth more than two. More specifically, his insight was that the shots most worth taking are higher percentage attempts near the basket (layups and dunks, ideally), or lower percentage ones that are further from the basket but are worth three points (free throws are also an important part of the equation in so-called Morey-Ball). This means that if a team’s goal is to get the most points out of every position (and that is every team’s goal), mid-range shots should be discouraged: They are harder to make than layups and dunks and still worth only two points.&lt;/p&gt;
&lt;p&gt;This has had a profound effect on how games are played and which players are valued. It wasn’t long ago that big men were expected to be able to post up near the basket and wouldn’t have to think about life outside the three-point arc. In 2019, a few games past the midpoint of the current season, Brook Lopez has already attempted 304 threes, Karl-Anthony Towns attempted 217, Marc Gasol attempted 193, Joel Embid attempted 178. Each of these players is listed as a center and is at least 7’0 feet tall. And the list goes on.&lt;/p&gt;
&lt;p&gt;And it’s not just who is shooting threes, it’s how they’re being shot. James Harden is setting new records for the number of &lt;a href=&#34;https://www.theringer.com/nba/2019/1/23/18193249/james-harden-scoring-history-houston-rockets&#34;&gt;unassisted threes made&lt;/a&gt;, meaning he doesn’t just shoot from deep as a compromise when better shots are not available, but it’s as if any shot that is &lt;em&gt;not&lt;/em&gt; a three is a compromise. Or consider Curry, for whom the three-point line itself is merely a suggestion; he has made &lt;a href=&#34;http://www.espn.com/nba/story/_/id/25771897/steph-curry-unleashing-impossible-range&#34;&gt;45 of 94 threes (47.9%!) launched from between 30 and 35 feet since 2014-2015&lt;/a&gt; (the line is 23 ft 9 inches from the basket, and 22 feet if you are standing in the corner).&lt;/p&gt;
&lt;p&gt;In 2019, you don’t have to watch games closely to notice the abundance of three pointers that are being shot. But still, I wanted to attach some numbers to the obvious, so below, I present a brief quantitative history of NBA three-point attempts.&lt;/p&gt;
&lt;div id=&#34;percentage-of-all-shot-attempts-that-were-threes&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Percentage of All Shot Attempts That Were Threes&lt;/h1&gt;
&lt;p&gt;It’s easy to forget how recent the explosion in three-point attempts has been. The chart below, which displays the percentage of all shot attempts that were threes, shows a gradual increase from 1998 to 2007. But from 2008 until 2012, the numbers leveled off, and it seemed peak-three had been reached. Then 2014 to 2018 happened, and the increase during that time period alone (7.77%) was greater than it was from all of 1998 to 2012 (6.65%)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/history-3s/history-of-basketball_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Although it’s a bit of an aside, despite the increase in the number of attempts, the percentage of three-pointers that have been made has remained relatively steady, as displayed below.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/history-3s/history-of-basketball_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;distribution-of-threes&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Distribution of Threes&lt;/h1&gt;
&lt;p&gt;As I mentioned above, three-point shots are no longer limited to certain positions, a point that is reflected in the histogram below. It shows players’ average number of three-point attempts per game along the x-axis, and the number of players falling within that range for the season is represented along the y-axis. Over time, notice how the distribution gets flatter. In 1998, the group who shot between zero and 0.5 threes per game appeared with the most frequency. But by 2018 that bar dropped significantly and the other bars lifted up. And pay attention to right side of the chart beginning in 2016.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/history-3s/history-of-basketball_files/figure-html/unnamed-chunk-4-1.gif&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;top-attempters-by-year&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Top Attempters by Year&lt;/h1&gt;
&lt;p&gt;Who are these gunners that are changing how basketball is played? The chart below displays the three players who averaged the most threes per game for each season from 1998 to 2018. Even the casual fan will not be surprised by the more recent appearances on the chart: Splash-Brothers Curry and Thompson; and Gordon and Harden, whose GM is the aforementioned Daryl Morey.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/history-3s/history-of-basketball_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;curry-explains-it-all&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Curry Explains it All&lt;/h1&gt;
&lt;p&gt;Daryl Morey’s influence on the game and the state of the evolution of the three-point shot is encapsulated by the shot charts below, which I downloaded using &lt;a href=&#34;https://github.com/toddwschneider/ballr&#34;&gt;Todd Schneider’s ballr package&lt;/a&gt;. The chart on the left is Stephen Curry’s shot chart from his 2009-2010 rookie season, and the shot chart on the right is from his 2017-2018 season. It’s almost as if during that time the in-between game disappeared, leaving only three point shots and shots at the basket. That, folks, is modern basketball.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/stephen-curry-2018-19-shot-chart-heat-map.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;The new style of play is not for everyone. Like any trend, this one can’t go on forever, but I do wonder how far it can go until it reaches a breaking point. Maybe the breaking point comes from the league if they decide to move the line &lt;a href=&#34;http://www.espn.com/blog/statsinfo/post/_/id/115055/what-moving-the-3-point-line-back-would-mean-for-warriors-nba&#34;&gt;further back&lt;/a&gt; or establish a &lt;a href=&#34;https://slate.com/culture/2016/06/the-4-point-line-could-be-coming-to-the-nba-heres-where-to-put-it.html&#34;&gt;four-point line&lt;/a&gt;. Or maybe it comes from the next Daryl Morey who discovers an inefficiency in the way the game is currently played. Either way, enjoy the show, because there is nothing quite like watching Stephen Curry casually make game winning shots from close to &lt;a href=&#34;https://www.youtube.com/watch?v=9dheZHuPSAo&#34;&gt;half court&lt;/a&gt;!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>An Analysis of Gender Disparity Among Higher Education Chief Administrators</title>
      <link>/post/gender-college-presidents/gender-college-presidents/</link>
      <pubDate>Fri, 24 Aug 2018 00:00:00 +0000</pubDate>
      <guid>/post/gender-college-presidents/gender-college-presidents/</guid>
      <description>


&lt;p&gt;The chief administrator job of a higher education institution is, as the title implies, the pinnacle of careers in academic administration. The chief administrator is a school’s spokesperson and guides its vision, affecting the lives of the thousands of students who pass through those institutions. And for the chief administrators who don’t care about the idealism of educating future generations, I would imagine the &lt;a href=&#34;https://www.chronicle.com/interactives/executive-compensation#id=table_public_2017&#34;&gt;high-six/low-seven figure salaries&lt;/a&gt; that many earn is incentive enough. Despite the prominent roles that these administrators fill, there is a dearth of publicly available data on them.&lt;/p&gt;
&lt;p&gt;Every institution that participates in federal student financial aid is required to submit data to Integrated Postsecondary Education System, or IPEDS. Eventually, the submitted data is made publicly available in the &lt;a href=&#34;https://nces.ed.gov/ipeds/use-the-data&#34;&gt;IPEDS Data Center&lt;/a&gt;. This includes numbers on admissions, student enrollment, degree completions, graduation rates, financial aid, finances, human resources, and libraries. Much of this data has to be reported by gender and race/ethnicity. For example, how many Hispanic female undergraduates began at an institution last fall? What is the graduation rate of male American Indian Alaska Natives? What is the average salary of female instructional staff on a 9-month contract? But for one reason or another, as far as I can tell, the only things that must be reported about an institution’s chief administrator are her or his name and title.&lt;/p&gt;
&lt;p&gt;Names, though, are not completely devoid of meaningful information. If you live in the United States and hear the name Steven, you probably think of a male, and if you hear the name Mary, you probably think of a female. Yes, some names are more ambiguous than others (my own being a good example), and some people’s names might belie the gender they identify with, but there is a degree of reliability that a person’s name offers in determining whether they are female or male. Thus, using first names to make educated guesses about chief administrators’ gender, my goal here was to describe gender representation among this set of individuals.&lt;/p&gt;
&lt;p&gt;The first step was to download the names of the chief administrators for every institution in the IPEDS Data Center (n = 7108) and clean up the data. This required putting years in a consistent format; removing titles preceding first names (e.g., Dr., Ms., Mrs.); extracting first names into their own column; and adding variable labels for college sector.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(babynames)
library(scales)

admin &amp;lt;- read_csv(&amp;quot;data/chief-admin-names.csv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# tidy year 
admin &amp;lt;- admin %&amp;gt;% 
  gather(&amp;quot;year&amp;quot;, &amp;quot;name&amp;quot;, `Name of chief administrator (HD2016)`,
         `Name of chief administrator (HD2015)`:`Name of Chief Administrator (IC90HD)`) 

# extract year from names and put in consistent format
admin &amp;lt;- admin %&amp;gt;% 
  mutate(year =  parse_number(year),
         year = ifelse(year &amp;gt;= 9596 &amp;amp; year &amp;lt;= 9798,
                       str_sub(start = 1, end = 2, year), year),
         year = ifelse(nchar(year) == 2, 
                       paste0(&amp;quot;19&amp;quot;, year), 
                       year),
         year = as.integer(year))

# select and rename variables
admin &amp;lt;- admin %&amp;gt;% 
  select(unit_id = UnitID, 
         sector_code = `Sector of institution (HD2016)`,
         institution_name = `Institution Name`,
         year, name,
         undergrad_enroll_2016 = `Grand total (EF2016  All students  Undergraduate total)`,
         grad_enroll_2016 = `Grand total (EF2016  All students  Graduate and First professional)`)

# titles are in the first position for many names, so need to remove
# those so can extract first posistion from names and have it reflect
# first name
admin &amp;lt;- admin %&amp;gt;% 
  mutate(name = tolower(name),
         name = gsub(&amp;quot;\\.&amp;quot;, &amp;quot;&amp;quot;, name),
         name = gsub(&amp;quot;\\&amp;lt;dr\\&amp;gt;&amp;quot;, &amp;quot;&amp;quot;, name),
         name = gsub(&amp;quot;\\&amp;lt;mr\\&amp;gt;&amp;quot;, &amp;quot;&amp;quot;, name),
         name = gsub(&amp;quot;\\&amp;lt;ms\\&amp;gt;&amp;quot;, &amp;quot;&amp;quot;, name),
         name = gsub(&amp;quot;\\&amp;lt;mrs\\&amp;gt;&amp;quot;, &amp;quot;&amp;quot;, name),
         name = gsub(&amp;quot;\\&amp;lt;rev\\&amp;gt;&amp;quot;, &amp;quot;&amp;quot;, name),
         name = gsub(&amp;quot;\\&amp;lt;reverend\\&amp;gt;&amp;quot;, &amp;quot;&amp;quot;, name),
         name = gsub(&amp;quot;\\&amp;lt;very reverend\\&amp;gt;&amp;quot;, &amp;quot;&amp;quot;, name),
         name = gsub(&amp;quot;\\&amp;lt;very\\&amp;gt;&amp;quot;, &amp;quot;&amp;quot;, name),
         name = gsub(&amp;quot;\\&amp;lt;rabbi\\&amp;gt;&amp;quot;, &amp;quot;&amp;quot;, name),
         name = gsub(&amp;quot;\\&amp;lt;msgr\\&amp;gt;&amp;quot;, &amp;quot;&amp;quot;, name),
         name = gsub(&amp;quot;\\&amp;lt;dra\\&amp;gt;&amp;quot;, &amp;quot;&amp;quot;, name),
         name = gsub(&amp;quot;\\&amp;lt;sr\\&amp;gt;&amp;quot;, &amp;quot;&amp;quot;, name),
         name = str_trim(name, side = &amp;quot;both&amp;quot;),
         full_name = tolower(name)) %&amp;gt;% 
  separate(name, into = &amp;quot;first_name&amp;quot;, sep = &amp;quot; &amp;quot;)

# add sector label
labels &amp;lt;- read_csv(&amp;quot;data/sector-value-labels.csv&amp;quot;) %&amp;gt;% 
  select(sector_code = Value, 
         sector_label = ValueLabel)

admin &amp;lt;- left_join(admin, labels, by = &amp;quot;sector_code&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, I assigned a gender to each chief administrator based on her or his first name. To do this, I used R’s &lt;code&gt;babynames&lt;/code&gt; package, which contains the number of babies born every year from 1880 to 2015 for each combination of name and sex&lt;a href=&#34;#fn1&#34; class=&#34;footnoteRef&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;. I took the babynames data and calculated how often each name was given to females vs. males, and then assigned gender based on the higher proportion. For example, in the babynames data, about 72% of all newborns named Jaydin were male, so I assigned the name Jaydin to male. Names like Jaydin, however, were the exception: Most of the time, names went overwhelmingly to one sex or the other, with the vast majority of names in the babynames dataset being associated with only one sex.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# read in babynames data and assign a proportion to female and male for each name
baby_names &amp;lt;- babynames %&amp;gt;% 
  select(sex, name, n) %&amp;gt;% 
  mutate(name = tolower(name))

baby_names &amp;lt;- baby_names %&amp;gt;% 
  group_by(sex, name) %&amp;gt;% 
  summarise(total = sum(n)) %&amp;gt;% 
  ungroup() %&amp;gt;% 
  group_by(name) %&amp;gt;% 
  mutate(prop = total/sum(total)) %&amp;gt;%
  filter(prop == max(prop)) %&amp;gt;% 
  ungroup() %&amp;gt;% 
  select(sex, first_name = name, prop)

# one chief admin officer has name gold and it happens to be one that is .5 prop,
# so removed from dataset. (gold was given as full name, so i&amp;#39;m *guessing* this 
# is actually last name).
baby_names &amp;lt;- baby_names %&amp;gt;% 
  filter(first_name != &amp;quot;gold&amp;quot; | prop != .5)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;historical-trends&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Historical Trends&lt;/h1&gt;
&lt;p&gt;This gave me a “dictionary” containing the probabilistic sex of 97,430 first names, which I then linked to the chief administrator data&lt;a href=&#34;#fn2&#34; class=&#34;footnoteRef&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;, making it possible to examine historical trends in gender differences among chief administrators. (The babynames data is based on sex, but once I link it to adults’ names (i.e., the administrators), I make the (often wrong) assumption that names reflect gender. Also, of course, with this data, it is not possible to account for gender non-binary administrators).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# join ipeds and babynames, removing rows where there were no matches
admin &amp;lt;- left_join(admin, baby_names, by = &amp;quot;first_name&amp;quot;) %&amp;gt;% 
  mutate(institution_name = gsub(&amp;quot;-&amp;quot;, &amp;quot; &amp;quot;, institution_name)) %&amp;gt;% 
  filter(!is.na(sex))

admin &amp;lt;- admin %&amp;gt;% 
  select(unit_id, institution_name, sector_label, year, undergrad_enroll_2016, 
         grad_enroll_2016, full_name, first_name, sex)

# several variables are for 2016 only, so put those in their own data frame
admin_2016 &amp;lt;- admin %&amp;gt;% 
  filter(year == 2016) %&amp;gt;% 
  select(-year)

admin &amp;lt;- admin %&amp;gt;% 
  select(-undergrad_enroll_2016, -grad_enroll_2016)

# proportion female by year
female_prop_sex &amp;lt;- admin %&amp;gt;% 
  count(year, sex) %&amp;gt;%
  group_by(year) %&amp;gt;% 
  mutate(year_total = sum(n)) %&amp;gt;% 
  ungroup() %&amp;gt;% 
  mutate(prop_sex = n/year_total) %&amp;gt;% 
  filter(sex == &amp;quot;F&amp;quot;)
  
female_prop_sex %&amp;gt;% 
  ggplot(aes(x = factor(year), y = prop_sex, group = 1)) +
  geom_line() +
  geom_point() +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  scale_y_continuous(label = percent_format()) +
  labs(x = &amp;quot;Year&amp;quot;, y = &amp;quot;Percent Women&amp;quot;,
       title = &amp;quot;Percentage of Chief Administrators Who Are Women&amp;quot;,
       subtitle = &amp;quot;All IPEDS Institutions, Years 1990-2016&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/gender-college-presidents/gender-college-presidents_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There are three things to notice about the chart:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;The increasing percentage of chief administrators who are women&lt;a href=&#34;#fn3&#34; class=&#34;footnoteRef&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;The still minority percentage of chief administrators who are women&lt;/li&gt;
&lt;li&gt;The 35% figure I came up with for 2016 is roughly consistent with a &lt;a href=&#34;http://www.acenet.edu/news-room/Documents/Leading-the-Way-to-Parity.pdf&#34;&gt;survey reporting that 30%&lt;/a&gt; of 2016 college presidents were women), and compatible with the trends reported &lt;a href=&#34;https://infogram.com/ready-to-lead-women-in-the-presidency-1h8n6me9o9392xo&#34;&gt;here&lt;/a&gt;, lending some support to the approach I selected.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;institution-type&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Institution Type&lt;/h1&gt;
&lt;p&gt;&lt;em&gt;School&lt;/em&gt;, as it’s used in IPEDS, is a broad term that covers vastly different types of institutions. It includes everything from a cosmetology school that enrolls a handful of students each year to flagship schools with billion-plus endowments and tens of thousands of students. That is to say, chief administrator positions vary in prestige, responsibility, salary, and a host of other intangibles. With that in mind, I calculated the percentage of female chief administrators, by sector.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# proportion female by sector
female_by_sector &amp;lt;- admin_2016 %&amp;gt;% 
  count(sector_label, sex) %&amp;gt;% 
  group_by(sector_label) %&amp;gt;% 
  mutate(prop_sex = n/sum(n)) %&amp;gt;% 
  ungroup() %&amp;gt;% 
  filter(sex == &amp;quot;F&amp;quot;)

female_by_sector %&amp;gt;%
  ggplot(aes(x = reorder(sector_label, prop_sex), y = prop_sex)) +
  geom_col() +
  coord_flip() +
  scale_y_continuous(label = percent_format()) +
  theme_minimal() +
  labs(x = NULL, y = &amp;quot;Percent Women&amp;quot;,
       title = &amp;quot;Percentage of Chief Aministrators Who Are Women,\nby Sector&amp;quot;,
       subtitle = &amp;quot;All IPEDS Institutions, Year 2016&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/gender-college-presidents/gender-college-presidents_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Although they are a minority in every sector, women make up a higher percentage of chief administrators at 2-year schools than at 4-year schools. One institution type is not better than another, but they serve different functions (e.g., teaching vs. research), meaning the disparities by sector further exaggerate the existing imbalance. For example, in 2016, 35.0% of academic chief administrators were women, yet the institutions they led accounted for only 28.5% of all students enrolled at institutions of higher education.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;The overall trend is moving in the right direction, but change is slow: From 1990 to 2016, the average yearly increase in the percentage of women chief administrators was 0.653%. These are prestigious jobs that aren’t vacated haphazardly, so for the near-term, the disparity is here to stay: If the same rate of change observed from 1990 to 2016 continues, it will take 23 years until gender parity among chief administrators is achieved.&lt;/p&gt;
&lt;p&gt;This is of course not a problem unique to higher education, but a societal one that begins well before women submit job applications. We must be aware of our biases - stop always telling your niece that she is pretty and her brother that he is smart! - however subtle they are, and correct them. You don’t have to be a woman to care about this, after all, “&lt;a href=&#34;https://www.pbs.org/weta/washingtonweek/web-video/hillary-clinton-declares-womens-rights-are-human-rights&#34;&gt;human rights are women’s rights&lt;/a&gt;”.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;The data is restricted to combinations of five for more.&lt;a href=&#34;#fnref1&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;I removed rows where there were no matches between first names in the IPEDS data and first names in the babynames data.&lt;a href=&#34;#fnref2&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;You may have noticed a slight dip from 2006 to 2009. Considering how abrupt it is, I’m skeptical it represents a real trend. My guess is that it is instead reflective of an unrelated change in the underlying data (e.g., different reporting requirements), but I’m not entirely sure.&lt;a href=&#34;#fnref3&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Popularity of Various Data Analytic Tools at AIR Forums</title>
      <link>/post/air-forum-text-software-frequency/air-forum-text-software-frequency/</link>
      <pubDate>Fri, 24 Aug 2018 00:00:00 +0000</pubDate>
      <guid>/post/air-forum-text-software-frequency/air-forum-text-software-frequency/</guid>
      <description>


&lt;p&gt;Data: It’s become a cliche to say that it’s everywhere and in quantities that are unimaginable. But data in its raw form, whether in a structured database or on the internet, is of limited use until a human does something to it: Gather it, clean it, visualize it, model it, write about it, and so-on.&lt;/p&gt;
&lt;p&gt;The amount of data that those in institutional research encounter requires powerful tools to work with. And those tools exist. Lots of them. Everything from free, open-source software, to software costing hundreds of thousands dollars offered by companies that won’t stop emailing you despite unsubscribing from their list on a weekly basis.&lt;/p&gt;
&lt;p&gt;On the rare occasion someone asks me which software I’d recommend, I always say R. In my experience, its ability to do everything you’d want and need to do as an institutional researcher is unmatched (cut to five minutes later when that someone regrets having asked me and is looking for ways to exit the conversation). But rather than use this space to drone on about why I think R is amazing, my goal here is to reveal the software preferences of others in the field. (And obviously, I used R to do this!)&lt;/p&gt;
&lt;p&gt;It’s not a perfect approach, but my thinking was I could see how often different tools were mentioned in AIR Forum program books and how that’s changed over time. My first step was to download the program books from the forum website going back six years. Next, I created a function to read each of the programs books into R and &lt;a href=&#34;https://www.tidyverse.org/&#34;&gt;tidy&lt;/a&gt; them so every individual word within each book is contained on its own line in a single data frame.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# load packages
library(pdftools)
library(tidyverse)
library(tidytext)
library(scales)

# function to read in PDFs and get one word per line.
text_prepr &amp;lt;- function(doc, forum_year){
  
  reg &amp;lt;- &amp;quot;([^A-Za-z\\d#@&amp;#39;]|&amp;#39;(?![A-Za-z\\d#@]))&amp;quot;
  
  df &amp;lt;- pdf_text(doc)
  
  df &amp;lt;- data.frame(df)

  df &amp;lt;- df %&amp;gt;%
    rename(text = df) %&amp;gt;%
    unnest_tokens(word, text,  token = &amp;quot;regex&amp;quot;, pattern = reg) %&amp;gt;%
    mutate(year = forum_year)
  
  return(df)
}

# apply function to programs books
all_years &amp;lt;- bind_rows(
  text_prepr(&amp;quot;data/AIR-2018-Forum-Program-Book.pdf&amp;quot;, 2018),
  text_prepr(&amp;quot;data/2017-AIR-Forum-Program-Book.pdf&amp;quot;, 2017),
  text_prepr(&amp;quot;data/2016_AIR-Forum_Program-Book.pdf&amp;quot;, 2016),
  text_prepr(&amp;quot;data/2015-Forum-Program-Book-Web.pdf&amp;quot;, 2015),
  text_prepr(&amp;quot;data/2014ForumProgramBookFinal.pdf&amp;quot;, 2014),
  text_prepr(&amp;quot;data/2013finalprogram.pdf&amp;quot;, 2013)
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This resulted in a data frame with a total 447583 rows (one row for each word), a glimpse of which is printed below:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(all_years)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            word year
## 1   association 2018
## 2           for 2018
## 3 institutional 2018
## 4      research 2018
## 5          2018 2018
## 6           may 2018&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, I decided on which words I would ask R to look for. Somewhat arbitrarily and somewhat based on my experience at AIR Forums, I chose the following: &lt;em&gt;Excel&lt;/em&gt;, &lt;em&gt;R&lt;/em&gt;, &lt;em&gt;SAS&lt;/em&gt;, &lt;em&gt;SPSS&lt;/em&gt;, and &lt;em&gt;Tableau&lt;/em&gt;. The code below (1) searches for mentions of those tools in the list of words created above (2) counts the results by year (3) builds a chart of the results. To clarify, the resulting chart displays the number of times each software is mentioned in each of the AIR Forum program books for each of the respective years.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# filter for keywords and count by word and year
software &amp;lt;- all_years %&amp;gt;% 
  mutate(word = tolower(word)) %&amp;gt;% 
  filter(word %in% c(&amp;quot;excel&amp;quot;, &amp;quot;r&amp;quot;, &amp;quot;sas&amp;quot;, &amp;quot;spss&amp;quot;, &amp;quot;tableau&amp;quot;)) %&amp;gt;% 
  count(word, year) %&amp;gt;% 
  complete(word, year, fill = list(n = 0))

# make data frame of only 2018, so can include as labels at end of lines
software_2018 &amp;lt;- software %&amp;gt;% 
  filter(year == 2018)

# create chart
ggplot() +
  geom_line(data = software, aes(x = year, y = n, color = word, group = word), size = 2) +
  geom_text(data = software_2018, aes(x = year, y = n, label = word), nudge_y = 2) +
  geom_point(data = software, aes(x = year, y = n, color = word), size = 3) +
  theme_minimal() +
  labs(x = &amp;quot;Forum Year&amp;quot;, y = &amp;quot;# of Mentions&amp;quot;,
       title = &amp;quot;Number of Times Software is Mentioned in AIR Forum Program Book&amp;quot;,
       subtitle = &amp;quot;2013 to 2018 Forums&amp;quot;) +
  guides(color = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/air-forum-text-software-frequency/air-forum-text-software-frequency_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;What stands out - and confirms what I’ve noticed at AIR Forums - is the rapid rise of Tableau. In 2014 I had never heard of it. In 2018, not knowing at least something about it seems unavoidable. Tableau is known for visual analytics, so it’s not surprising that its rise in populairty has coincided with an increasing interest in data visualization at AIR Forums.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# filter for keyword and count by word and year
visualize &amp;lt;- all_years %&amp;gt;% 
  group_by(year) %&amp;gt;% 
  mutate(total = n()) %&amp;gt;% 
  ungroup() %&amp;gt;% 
  mutate(visualiz = str_detect(word, &amp;quot;visualiz&amp;quot;)) %&amp;gt;%
  group_by(year) %&amp;gt;% 
  summarise(prop = mean(visualiz)) %&amp;gt;% 
  ungroup()


# create chart
ggplot(visualize, aes(x = year, y = prop)) +
  geom_line(size = 2) +
  geom_point(size = 3) +
  theme_minimal() +
  labs(x = &amp;quot;Forum Year&amp;quot;, y = &amp;quot;% of Mentions&amp;quot;,
       title = &amp;#39;Percent of All Words That Were &amp;quot;Visualiz*&amp;quot; in AIR Forum Program Book&amp;#39;,
       subtitle = &amp;quot;2013 to 2018 Forums&amp;quot;) +
  guides(color = FALSE) +
  scale_y_continuous(label = percent_format())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/air-forum-text-software-frequency/air-forum-text-software-frequency_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Returning to the first chart, perhaps it’s my background in psychology - a field which has historically been dominated by SPSS - but I was surprised how little SPSS is mentioned (although, I wouldn’t be surprised to see it decrease in the future). As for R, it seems to have a presence, but I’m curious to see what happens to its popularity in institutional research over the next few years. Judging by my experience at recent Forums and the development of R tools that decrease the barrier to entry, my prediction is that interest will only grow.&lt;/p&gt;
&lt;p&gt;I’m not sure if this need be said, but I will: This approach to evaluating software popularity is fraught with limitations. My goal, however, was not to get a precise estimate. Rather, I was interested in one, getting a general sense of broad trends, and two, sharing how just a little of bit R code can do so much!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Achieving Reproducibility in IR With R</title>
      <link>/talk/2018-air/</link>
      <pubDate>Thu, 31 May 2018 10:45:00 +0000</pubDate>
      <guid>/talk/2018-air/</guid>
      <description>


&lt;p&gt;Although the concept of reproducibility is typically reserved for the sciences, the presenter will argue that by adopting its principles, IR offices would see immeasurable benefits in efficiency, accuracy, and transparency. Reproducible workflows preserve every decision made about data analyses (e.g., removing a student who withdrew) and allow users to quickly and accurately respond to requests for modifications (e.g., group tables by college instead of major). One barrier to reproducibility, however, is that it requires coding. Using examples from the free R programming language, the presenter will show that not only is R an ideal software for reproducibility, but that many of its modern features are designed to get novices quickly doing powerful things. The primary goals of the presentation are for audience members to leave convinced that they can learn R, and that if they do, they will become better at their jobs.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Data Visualization Showcase</title>
      <link>/talk/2017-air/</link>
      <pubDate>Tue, 30 May 2017 15:30:00 +0000</pubDate>
      <guid>/talk/2017-air/</guid>
      <description>


&lt;p&gt;Although the concept of reproducibility is typically reserved for the sciences, the presenter will argue that by adopting its principles, IR offices would see immeasurable benefits in efficiency, accuracy, and transparency. Reproducible workflows preserve every decision made about data analyses (e.g., removing a student who withdrew) and allow users to quickly and accurately respond to requests for modifications (e.g., group tables by college instead of major). One barrier to reproducibility, however, is that it requires coding. Using examples from the free R programming language, the presenter will show that not only is R an ideal software for reproducibility, but that many of its modern features are designed to get novices quickly doing powerful things. The primary goals of the presentation are for audience members to leave convinced that they can learn R, and that if they do, they will become better at their jobs.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Creating Data Visualizations Using R: An Introduction for Non-Programmers</title>
      <link>/talk/2016-air/</link>
      <pubDate>Fri, 01 Jul 2016 15:00:00 +0000</pubDate>
      <guid>/talk/2016-air/</guid>
      <description>


&lt;p&gt;Although the concept of reproducibility is typically reserved for the sciences, the presenter will argue that by adopting its principles, IR offices would see immeasurable benefits in efficiency, accuracy, and transparency. Reproducible workflows preserve every decision made about data analyses (e.g., removing a student who withdrew) and allow users to quickly and accurately respond to requests for modifications (e.g., group tables by college instead of major). One barrier to reproducibility, however, is that it requires coding. Using examples from the free R programming language, the presenter will show that not only is R an ideal software for reproducibility, but that many of its modern features are designed to get novices quickly doing powerful things. The primary goals of the presentation are for audience members to leave convinced that they can learn R, and that if they do, they will become better at their jobs.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
